{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volumetric Stiffness Field Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "***  klampt.vis: using Qt6 as the visualization backend  ***\n"
     ]
    }
   ],
   "source": [
    "# Auto reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#if you haven't installed vsf and just want to run this from the current directory, uncomment the following lines\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from vsf import vsf_from_file\n",
    "from klampt.io import open3d_convert\n",
    "from klampt import vis, Geometry3D, WorldModel\n",
    "from vsf.visualize.klampt_visualization import vsf_show\n",
    "\n",
    "vis.init('PyQt')  #needed to pop up Klampt OpenGL windows in Jupyter notebook\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Demo Data\n",
    "\n",
    "Download the demo data from the following link:  \n",
    "**https://uofi.box.com/s/31wozq63qgqvg8012r1jdfj5mdchmmfp**\n",
    "\n",
    "After extracting, place the `demo_data` folder in the `openvsf` directory as `openvsf/demo_data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a VSF from file\n",
    "\n",
    "In this example we will load one of the demo objects.  Let's assume that you have placed `demo_data` in the parent directory of this Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "vsf_model = vsf_from_file('../demo_data/saved_vsfs/rubber_fig_tall_angle00/vsf.npz')\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the loaded model.  We can do so in Open3D using a point cloud visualization, or in Klampt with a point cloud or implicit surface visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stiffness range:  -3.0433426e-18 40.33515\n"
     ]
    }
   ],
   "source": [
    "# Visualize VSF point cloud in Open3D\n",
    "import open3d as o3d\n",
    "from vsf.visualize.o3d_visualization import vsf_to_point_cloud\n",
    "vis_pcd = vsf_to_point_cloud(vsf_model)\n",
    "o3d.visualization.draw_geometries([vis_pcd], window_name='VSF vis_pcd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stiffness range:  -3.0433426e-18 40.33515\n",
      "################################################################\n",
      "klampt.vis: Running multi-threaded dialog, waiting to complete...\n",
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Dialog on window 1 starting\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWidget.initialize: no action menu?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: QApplication was not created in the main() thread.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n",
      "#########################################\n",
      "klampt.vis: Dialog done on window 1 result 0\n",
      "#########################################\n",
      "klampt.vis: ... dialog done, leaving thread open\n",
      "################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Making window 0\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n",
      "#########################################\n",
      "klampt.vis: Window 0 close\n",
      "#########################################\n",
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Dialog on window 2 starting\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWidget.initialize: no action menu?\n",
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n",
      "#########################################\n",
      "klampt.vis: Dialog done on window 2 result 0\n",
      "#########################################\n",
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Dialog on window 3 starting\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWidget.initialize: no action menu?\n",
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n",
      "#########################################\n",
      "klampt.vis: Dialog done on window 3 result 0\n",
      "#########################################\n",
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Dialog on window 4 starting\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWidget.initialize: no action menu?\n",
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n",
      "#########################################\n",
      "klampt.vis: Dialog done on window 4 result 0\n",
      "#########################################\n",
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Dialog on window 5 starting\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWidget.initialize: no action menu?\n",
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n",
      "#########################################\n",
      "klampt.vis: Dialog done on window 5 result 0\n",
      "#########################################\n",
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Dialog on window 6 starting\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWidget.initialize: no action menu?\n",
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n",
      "#########################################\n",
      "klampt.vis: Dialog done on window 6 result 0\n",
      "#########################################\n",
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Dialog on window 7 starting\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWidget.initialize: no action menu?\n",
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n",
      "#########################################\n",
      "klampt.vis: Dialog done on window 7 result 0\n",
      "#########################################\n",
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Dialog on window 8 starting\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWidget.initialize: no action menu?\n",
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n",
      "#########################################\n",
      "klampt.vis: Dialog done on window 8 result 0\n",
      "#########################################\n",
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Dialog on window 9 starting\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWidget.initialize: no action menu?\n",
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n",
      "#########################################\n",
      "klampt.vis: Dialog done on window 9 result 0\n",
      "#########################################\n",
      "#########################################\n",
      "klampt.vis: Making window 0\n",
      "#########################################\n",
      "#########################################\n",
      "klampt.vis: Window 0 close\n",
      "#########################################\n",
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Dialog on window 10 starting\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWidget.initialize: no action menu?\n",
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n",
      "#########################################\n",
      "klampt.vis: Dialog done on window 10 result 0\n",
      "#########################################\n",
      "#########################################\n",
      "klampt.vis: Making window 0\n",
      "#########################################\n",
      "#########################################\n",
      "klampt.vis: Window 0 close\n",
      "#########################################\n",
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Dialog on window 11 starting\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWidget.initialize: no action menu?\n",
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n",
      "#########################################\n",
      "klampt.vis: Dialog done on window 11 result 0\n",
      "#########################################\n",
      "#########################################\n",
      "klampt.vis: Making window 0\n",
      "#########################################\n",
      "#########################################\n",
      "klampt.vis: Window 0 close\n",
      "#########################################\n"
     ]
    }
   ],
   "source": [
    "# Klampt point cloud visualization of VSF\n",
    "from vsf.visualize.klampt_visualization import vsf_to_point_cloud\n",
    "k_pcd = Geometry3D(vsf_to_point_cloud(vsf_model))\n",
    "vis.debug(k_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting voxel grid resolution 0.021477368597769594\n",
      "klampt.vis: auto-fitting camera to scene.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized OpenGL version\n",
      "Unrecognized OpenGL version\n"
     ]
    }
   ],
   "source": [
    "# Klampt volumetric visualization of VSF\n",
    "stiffness_levels = [0.27072093, 4.54502328, 8.81932563, 9.09362797, 10.36793032]\n",
    "vsf_show(vsf_model, stiffness_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VSF estimation from tactile data\n",
    "\n",
    "In this example, we will create VSF from a dataset that includes tactile observations.\n",
    "\n",
    "- Create an empty VSF.  We will use a VSFFactory to shape the VSF rest points from an RGBD point cloud\n",
    "- Configure the robot model and sensor(s).  In this case the robot is a Kinova Gen3, and there is only one sensor that provides joint torques.\n",
    "- Load a dataset of sequences giving robot actions and observations from sensor(s) \n",
    "- Create an estimator, and run it in batch mode on the dataset.\n",
    "\n",
    "Let's start by creating an empty VSF.  If you have an RGB-D scanned object, you should use a `VSFRGBDCameraFactory` like the following code to construct the VSF points from a region of interest in the point cloud, extending through a volume behind the camera's point of view.  It doesn't really matter how you get the points; you can also create an empty box using the `vsf.vsf_from_box()` function, create a VSF from a 3D scanned mesh using `vsf.vsf_from_mesh()`, or load a previously saved VSF from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBox selection: keeping 129694 points out of 459947\n",
      "downsampling visual point cloud to voxel size 0.02\n",
      "iter step 0 left pts: 129694\n",
      "iter step 1 left pts: 129666\n",
      "iter step 2 left pts: 129567\n",
      "iter step 3 left pts: 129479\n",
      "iter step 4 left pts: 129241\n",
      "iter step 5 left pts: 129014\n",
      "iter step 6 left pts: 128862\n",
      "iter step 7 left pts: 128657\n",
      "iter step 8 left pts: 128345\n",
      "iter step 9 left pts: 128086\n",
      "iter step 10 left pts: 127695\n",
      "iter step 11 left pts: 127290\n",
      "iter step 12 left pts: 126953\n",
      "iter step 13 left pts: 126644\n",
      "iter step 14 left pts: 126349\n",
      "iter step 15 left pts: 126033\n",
      "iter step 16 left pts: 125654\n",
      "iter step 17 left pts: 125288\n",
      "iter step 18 left pts: 124893\n",
      "iter step 19 left pts: 124478\n",
      "iter step 20 left pts: 124064\n",
      "iter step 21 left pts: 123677\n",
      "iter step 22 left pts: 123282\n",
      "iter step 23 left pts: 122795\n",
      "iter step 24 left pts: 121882\n",
      "iter step 25 left pts: 120518\n",
      "iter step 26 left pts: 118863\n",
      "iter step 27 left pts: 117332\n",
      "iter step 28 left pts: 114992\n",
      "iter step 29 left pts: 110272\n",
      "iter step 30 left pts: 101861\n",
      "iter step 31 left pts: 91698\n",
      "iter step 32 left pts: 79514\n",
      "iter step 33 left pts: 66521\n",
      "iter step 34 left pts: 56075\n",
      "iter step 35 left pts: 47921\n",
      "iter step 36 left pts: 40719\n",
      "iter step 37 left pts: 34362\n",
      "iter step 38 left pts: 28862\n",
      "iter step 39 left pts: 24818\n",
      "iter step 40 left pts: 21681\n",
      "iter step 41 left pts: 19139\n",
      "iter step 42 left pts: 16206\n",
      "iter step 43 left pts: 13074\n",
      "iter step 44 left pts: 9662\n",
      "iter step 45 left pts: 6991\n",
      "iter step 46 left pts: 5212\n",
      "iter step 47 left pts: 3747\n",
      "iter step 48 left pts: 2268\n",
      "iter step 49 left pts: 1207\n",
      "number of surface points: 1978\n",
      "number of volume points: 24599\n",
      "26577 rest points for VSF model created from RGBD factory\n"
     ]
    }
   ],
   "source": [
    "from vsf.core.vsf_factory import VSFRGBDCameraFactory, VSFRGBDCameraFactoryConfig, ViewConfig\n",
    "\n",
    "view = ViewConfig(origin=[-0.55639158,1.04689234,0.52593784])  # need to set the origin of the camera so that volume points can be created\n",
    "#we will select points within a bounding box \n",
    "config = VSFRGBDCameraFactoryConfig(features=['color'], voxel_size=0.02,\n",
    "                                    view = view, bbox = [[-1.03, -0.64, -0.22], [-0.29, 0.23, 0.73]], downsample_visual=True, verbose=True)\n",
    "factory = VSFRGBDCameraFactory(config)\n",
    "#process() does all the work\n",
    "vsf_empty = factory.process('../demo_data/datasets/rubber_fig_tall_angle00/object/bg_pcd.pcd')  #the PCD file is the point cloud of the RGBD scene, including the background \n",
    "print('{} rest points for VSF model created from RGBD factory'.format(len(vsf_empty.rest_points)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stiffness range:  0.0 0.0\n",
      "#########################################\n",
      "klampt.vis: Creating dialog on window 2\n",
      "#########################################\n",
      "vis.dialog(): waiting for window 2 on vis thread to complete....\n",
      "vis.dialog(): ... dialog done\n"
     ]
    }
   ],
   "source": [
    "# Show the processed VSF model\n",
    "from vsf.visualize.klampt_visualization import vsf_to_point_cloud\n",
    "vis.debug(empty_pc = vsf_to_point_cloud(vsf_empty, masked_view_fraction=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a world with a robot, a simulator, and one or more sensors.  This example loads a Kinova Gen3 robot model and uses the joint torque sensors in the simulator.  We also add the empty VSF into the simulator using `sim.add_deformable`.  This creates a body that can be moved through space.  (By default, all VSFs are considered to have a static pose, which works well if the object doesn't move much during interaction.  We will consider moving objects later.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorldModel::LoadRobot: ../knowledge/robot_model/kinova_gen3.urdf\n",
      "URDFParser: Link size: 9\n",
      "URDFParser: Joint size: 9\n",
      "URDFParser: Done loading robot file ../knowledge/robot_model/kinova_gen3.urdf\n",
      "Warning: model EndEffector_Link type  is not triangle mesh\n",
      "FMM_Fill identifies 1305 surface, 731 interior, 2003 exterior cells\n",
      "FMM starting with 835 surface cells, grid of size 13 13 21\n",
      "FMM found 1151 interior and 2398 exterior cells\n",
      "Geometry: AnyGeometry::Convert: FMM grid bounding box -0.0648063 -0.0649216 -0.019575   0.0651937 0.0650784 0.190425\n",
      "FMM_Fill identifies 1076 surface, 539 interior, 1737 exterior cells\n",
      "FMM starting with 684 surface cells, grid of size 13 13 21\n",
      "FMM found 867 interior and 2682 exterior cells\n",
      "Geometry: AnyGeometry::Convert: FMM grid bounding box -0.065 -0.0662972 -0.193375   0.065 0.0637028 0.016625\n",
      "FMM_Fill identifies 1503 surface, 788 interior, 2376 exterior cells\n",
      "FMM starting with 829 surface cells, grid of size 13 31 13\n",
      "FMM found 1113 interior and 4126 exterior cells\n",
      "Geometry: AnyGeometry::Convert: FMM grid bounding box -0.065 -0.2444 -0.0728769   0.065 0.0656 0.0571231\n",
      "TriMeshTopology: mesh has 7 triangles with duplicate neighbors!\n",
      "  Triangle range 2410 to 2722\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 7 triangles with duplicate neighbors!\n",
      "  Triangle range 2410 to 2722\n",
      "  May see strange results for some triangle mesh operations\n",
      "FMM_Fill identifies 1358 surface, 699 interior, 2167 exterior cells\n",
      "FMM starting with 781 surface cells, grid of size 13 13 28\n",
      "FMM found 1077 interior and 3655 exterior cells\n",
      "Geometry: AnyGeometry::Convert: FMM grid bounding box -0.065 -0.0665021 -0.275775   0.065 0.0634979 0.00422499\n",
      "TriMeshTopology: mesh has 22 triangles with duplicate neighbors!\n",
      "  Triangle range 1990 to 3298\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 22 triangles with duplicate neighbors!\n",
      "  Triangle range 1990 to 3298\n",
      "  May see strange results for some triangle mesh operations\n",
      "FMM_Fill identifies 1122 surface, 526 interior, 1868 exterior cells\n",
      "FMM starting with 686 surface cells, grid of size 13 30 12\n",
      "FMM found 821 interior and 3859 exterior cells\n",
      "Geometry: AnyGeometry::Convert: FMM grid bounding box -0.065 -0.23745 -0.0736478   0.065 0.06255 0.0463522\n",
      "FMM_Fill identifies 522 surface, 210 interior, 930 exterior cells\n",
      "FMM starting with 472 surface cells, grid of size 10 12 17\n",
      "FMM found 442 interior and 1598 exterior cells\n",
      "Geometry: AnyGeometry::Convert: FMM grid bounding box -0.0499992 -0.0690232 -0.156752   0.0500008 0.0509768 0.0132482\n",
      "TriMeshTopology: mesh has 18 triangles with duplicate neighbors!\n",
      "  Triangle range 4061 to 4257\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 18 triangles with duplicate neighbors!\n",
      "  Triangle range 4061 to 4257\n",
      "  May see strange results for some triangle mesh operations\n",
      "FMM_Fill identifies 510 surface, 190 interior, 932 exterior cells\n",
      "FMM starting with 484 surface cells, grid of size 10 19 12\n",
      "FMM found 396 interior and 1884 exterior cells\n",
      "Geometry: AnyGeometry::Convert: FMM grid bounding box -0.05 -0.136661 -0.0692511   0.05 0.0533391 0.0507489\n",
      "FMM_Fill identifies 290 surface, 100 interior, 548 exterior cells\n",
      "FMM starting with 317 surface cells, grid of size 11 11 10\n",
      "FMM found 254 interior and 956 exterior cells\n",
      "Geometry: AnyGeometry::Convert: FMM grid bounding box -0.0550454 -0.055 -0.0834625   0.0549546 0.055 0.0165375\n"
     ]
    }
   ],
   "source": [
    "from vsf.sim import klamptWorldWrapper, QuasistaticVSFSimulator\n",
    "from vsf.sim.point_vsf_body import ContactParams\n",
    "from vsf.sensor.joint_torque_sensor import JointTorqueSensor\n",
    "\n",
    "#create a world\n",
    "world = klamptWorldWrapper()\n",
    "world.add_robot('kinova','../knowledge/robot_model/kinova_gen3.urdf')\n",
    "robot = world.world.robot(0)\n",
    "\n",
    "#this preprocessing needs to be done before running the simulator with a point VSF body\n",
    "world.setup_local_pcd_lst('open3d')\n",
    "world.setup_local_sdf_lst()\n",
    "\n",
    "#create a simulator with the world, a joint torque sensor, and the vsf body\n",
    "sensor = JointTorqueSensor('kinova_joint_torques','kinova',[robot.link(i).name for i in range(1,8)])\n",
    "sim = QuasistaticVSFSimulator(world, [sensor])\n",
    "vsf_body = sim.add_deformable('vsf',vsf_empty, contact_params=None)  #if you want to customize how the VSF is simulated, you can pass in a ContactParams object here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stiffness range:  0.0 0.0\n",
      "#########################################\n",
      "klampt.vis: Creating dialog on window 3\n",
      "#########################################\n",
      "vis.dialog(): waiting for window 3 on vis thread to complete....\n",
      "TriMeshTopology: mesh has 9 triangles with duplicate neighbors!\n",
      "  Triangle range 273 to 924\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 104 triangles with duplicate neighbors!\n",
      "  Triangle range 3828 to 4274\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 271 triangles with duplicate neighbors!\n",
      "  Triangle range 80 to 3362\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 635 triangles with duplicate neighbors!\n",
      "  Triangle range 29 to 3626\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 587 triangles with duplicate neighbors!\n",
      "  Triangle range 1988 to 3472\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 344 triangles with duplicate neighbors!\n",
      "  Triangle range 4000 to 5015\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 344 triangles with duplicate neighbors!\n",
      "  Triangle range 3199 to 4281\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 378 triangles with duplicate neighbors!\n",
      "  Triangle range 2 to 8834\n",
      "  May see strange results for some triangle mesh operations\n",
      "vis.dialog(): ... dialog done\n"
     ]
    }
   ],
   "source": [
    "# show the world and VSF\n",
    "from vsf.visualize.klampt_visualization import vsf_to_point_cloud\n",
    "vis.debug(world=world.world, empty_pc = vsf_to_point_cloud(vsf_empty), origin = view.origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will set up a dataset. We will load a dataset from a standard folder format, which is configured and loaded automatically in the following example.  We will use a `DatasetConfig` which specifies which keys are present, and which keys used for robot commands and sensor observations.  The `dataset_from_config` function will set up a dataset appropriately to follow the specified configuration.  The standard dataset lazy-loads sequences into memory.\n",
    "\n",
    "More generally, a dataset is any object that can be treated like a list of sequences, and each sequence is a list of dictionaries mapping keys to numpy arrays.  In other words, datasets behave like a `List[List[Dict[str,np.ndarray]]]` type. If you don't want to go through the trouble of saving such a thing to disk, you can just create such an object yourself.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 32 sequences\n"
     ]
    }
   ],
   "source": [
    "from vsf.dataset.constructors import DatasetConfig, dataset_from_config\n",
    "\n",
    "keys = {'kinova_joint_torques':7,'kinova_state':7}  #describes the keys present in the dataset\n",
    "dataset_config = DatasetConfig(type='joint_torque_dataset', \n",
    "                               path='../demo_data/datasets/rubber_fig_tall_angle00/split1',\n",
    "                               keys=keys,\n",
    "                               sensor_keys={'kinova_joint_torques':'kinova_joint_torques'},\n",
    "                               control_keys={'kinova':'kinova_state'})\n",
    "dataset = dataset_from_config(dataset_config)\n",
    "print(\"Dataset has {} sequences\".format(len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For debugging, let's just validate the trajectories coming from the dataset.  Here we'll show the first 5 trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704083702\n",
      "Stiffness range:  0.0 0.0\n",
      "#########################################\n",
      "klampt.vis: Creating dialog on window 4\n",
      "#########################################\n",
      "vis.dialog(): waiting for window 4 on vis thread to complete....\n",
      "vis.dialog(): ... dialog done\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704083759\n",
      "Stiffness range:  0.0 0.0\n",
      "#########################################\n",
      "klampt.vis: Creating dialog on window 5\n",
      "#########################################\n",
      "vis.dialog(): waiting for window 5 on vis thread to complete....\n",
      "vis.dialog(): ... dialog done\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704083799\n",
      "Stiffness range:  0.0 0.0\n",
      "#########################################\n",
      "klampt.vis: Creating dialog on window 6\n",
      "#########################################\n",
      "vis.dialog(): waiting for window 6 on vis thread to complete....\n",
      "vis.dialog(): ... dialog done\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704083834\n",
      "Stiffness range:  0.0 0.0\n",
      "#########################################\n",
      "klampt.vis: Creating dialog on window 7\n",
      "#########################################\n",
      "vis.dialog(): waiting for window 7 on vis thread to complete....\n",
      "vis.dialog(): ... dialog done\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704083869\n",
      "Stiffness range:  0.0 0.0\n",
      "#########################################\n",
      "klampt.vis: Creating dialog on window 8\n",
      "#########################################\n",
      "vis.dialog(): waiting for window 8 on vis thread to complete....\n",
      "vis.dialog(): ... dialog done\n"
     ]
    }
   ],
   "source": [
    "from klampt.model.trajectory import RobotTrajectory \n",
    "\n",
    "for seqno in range(len(dataset)):\n",
    "    #extract the sequence of commands\n",
    "    seq = dataset[seqno]\n",
    "    commands = []\n",
    "    for frame in range(len(seq)):\n",
    "        frame = seq[frame]\n",
    "        commands.append(frame['kinova_state'])\n",
    "\n",
    "    #convert to a RobotTrajectory and show it\n",
    "    configs = [robot.configFromDrivers(d) for d in commands]\n",
    "    traj = RobotTrajectory(robot,[i/len(configs) for i in range(len(configs))],configs)\n",
    "    vis.debug(robot, {'animation':traj}, 'empty_pc', vsf_to_point_cloud(vsf_empty))\n",
    "    if seqno >= 4: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the discrepancy between the observations and the predicted measurements for a random VSF stiffness.  Here, we're also introducing the notion of sensor calibration, which is usually necessary at the beginning of a trial to tare the values coming from the sensor.\n",
    "\n",
    "A `BaseSensor` can potentially handle its own calibration, but we find it's easier to separate how to calibrate the sensor from the sensor simulator itself.  Here we will generate a `BaseCalibrator` object that we will run at the beginning of each trial to calibrate the sensor.\n",
    "\n",
    "(There is a little bit of work here to convert the dataset keys to the control and sensor keys expected by the simulator, calibrator, and estimators. This boilerplate is used a lot...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 0 calibration: {'tare': array([ 0.45979138, 18.23648429,  0.42123438,  2.86159472,  0.06669243,\n",
      "       -0.8061054 , -0.30282573]), 'gravity_pred_at_tare': array([-1.35915481e-04,  1.91127152e+01,  2.38662322e-01,  2.89546379e+00,\n",
      "        5.89215163e-02, -9.54574667e-01, -7.94720591e-03])}\n",
      "Sequence 0 joint torque RMSEs [9.17827463 3.28268953 4.65815837 1.8208583  0.497117   0.48569154\n",
      " 0.09726507]\n",
      "Sequence 1 calibration: {'tare': array([ 0.52451001, 19.72127437, -0.08059071,  3.76032879,  0.34009876,\n",
      "       -0.71614274, -0.38496185]), 'gravity_pred_at_tare': array([ 4.59781161e-01,  1.96244829e+01, -3.01500764e-03,  4.47961341e+00,\n",
      "        3.32438221e-01, -7.43565164e-01, -2.97378133e-01])}\n",
      "Sequence 1 joint torque RMSEs [5.65413786 2.84083297 3.03784157 0.67209229 0.88973262 0.58248435\n",
      " 0.26551973]\n",
      "Sequence 2 calibration: {'tare': array([ 0.37255337, 18.40848739,  0.55852668,  3.35344802,  0.42691417,\n",
      "       -0.49719183, -0.20882375]), 'gravity_pred_at_tare': array([ 0.06459304, 19.26186309, -0.12593415,  3.38354258,  0.31101709,\n",
      "       -0.85250602, -0.10024354])}\n",
      "Sequence 2 joint torque RMSEs [4.60713801 0.86202735 1.58330786 0.94168614 0.32394828 0.18022687\n",
      " 0.28451749]\n",
      "Sequence 3 calibration: {'tare': array([ 0.28940828, 17.29808536,  0.54911277,  3.54118616,  0.25892454,\n",
      "       -0.88644777, -0.30227018]), 'gravity_pred_at_tare': array([ 0.30782696, 17.60634385,  0.83153722,  3.84451151,  0.32319579,\n",
      "       -0.5830454 , -0.10591994])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/motion/openvsf/demos/../vsf/sensor/base_calibrator.py:78: UserWarning: Contact happens at the first sample, please check the command sequence\n",
      "  warnings.warn('Contact happens at the first sample, please check the command sequence')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 3 joint torque RMSEs [3.66120027 1.39108469 1.81534631 0.98915593 0.36882628 0.74600637\n",
      " 0.06405179]\n",
      "Sequence 4 calibration: {'tare': array([ 0.44969128, 14.27508675, -0.23326894,  5.27838991,  0.40612126,\n",
      "       -0.73751265, -0.04340425]), 'gravity_pred_at_tare': array([-0.01852482, 15.00579225, -0.89109171,  5.63442993, -0.02772186,\n",
      "       -1.27192794, -0.18563287])}\n",
      "Sequence 4 joint torque RMSEs [0.23552134 0.66598655 0.23684952 0.77890765 0.10500587 0.46168744\n",
      " 0.11577801]\n"
     ]
    }
   ],
   "source": [
    "from vsf.sensor import TareCalibrator\n",
    "import numpy as np\n",
    "\n",
    "vsf_empty.stiffness.fill_(0.1)  #set a guessed stiffness of the VSF model\n",
    "calibrator = TareCalibrator()\n",
    "for seqno in range(len(dataset)):\n",
    "    #extract the sequence of controls and observations.  This is boilerplate\n",
    "    seq = dataset[seqno]\n",
    "    control_seq = []\n",
    "    sensor_seq = []\n",
    "    for frame in seq:\n",
    "        control_seq.append({k:frame[v] for k,v in dataset_config.control_keys.items()})\n",
    "        sensor_seq.append({k:frame[v] for k,v in dataset_config.sensor_keys.items()})\n",
    "        \n",
    "    #run the calibration\n",
    "    sim.reset()\n",
    "    n = calibrator.calibrate(sensor,sim,control_seq,sensor_seq)\n",
    "    #returns the # of samples used in calibration.  Technically should skip this number of frames for estimation\n",
    "    print(\"Sequence\",seqno,\"calibration:\",sensor.get_calibration())\n",
    "\n",
    "    #now, run the simulator and compare the predicted torques to the actual torques\n",
    "    dt = 0.1  # a guessed time step.  There's no time-dependent functionality in the quasistatic simulator, so this doesn't matter\n",
    "    diffs = []\n",
    "    for frameno in range(n,len(seq)):\n",
    "        sim.step(control_seq[frameno],dt)\n",
    "        pred = sim.measurements()['kinova_joint_torques'].numpy()\n",
    "        actual = sensor_seq[frameno]['kinova_joint_torques']\n",
    "        assert len(pred) == len(actual)\n",
    "        diffs.append(pred-actual)\n",
    "    diffs = np.array(diffs)\n",
    "    print(\"Sequence\",seqno,\"joint torque RMSEs\",np.sqrt(np.mean(diffs**2,axis=0)))\n",
    "\n",
    "    if seqno >= 4: break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's start the estimation process.  Let's start by using *batch* estimation, which uses all the items in the dataset to estimate the VSF stiffness parameters.  We have to provide a prior to the estimator to initialize its stiffness guess, and we will use a GaussianVSFPriorFactory which assigns an independent Gaussian distribution to each point's stiffness.\n",
    "\n",
    "We can also customize the configuration of the estimator, such as the optimization technique used, but let's not worry about this too much for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating simulation cache\n",
      "Number of observations: 5\n",
      "Observed indices: 2070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/motion/miniconda3/envs/vsf/lib/python3.10/site-packages/cvxpy/problems/problem.py:158: UserWarning: Objective contains too many subexpressions. Consider vectorizing your CVXPY code to speed up compilation.\n",
      "  warnings.warn(\"Objective contains too many subexpressions. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuadProgOptimizer: start solving cvxpy problem...\n",
      "QuadProgOptimizer: cvxpy solve time = 6.429910898208618\n",
      "Estimation took time 12.938708066940308\n"
     ]
    }
   ],
   "source": [
    "from vsf.sensor import TareCalibrator\n",
    "from vsf.estimator.point_vsf_estimator import PointVSFEstimator, PointVSFEstimatorConfig\n",
    "from vsf.prior.prior_factory import GaussianVSFPriorFactory\n",
    "import time\n",
    "import copy\n",
    "vsf_est = vsf_empty\n",
    "vsf_empty = copy.deepcopy(vsf_est)  #save a copy of the uninitialized VSF for later\n",
    "\n",
    "#the second argument sets the prior estimate to a mean of 0.1 and a standard deviation of 1.0\n",
    "estimator = PointVSFEstimator(PointVSFEstimatorConfig(), GaussianVSFPriorFactory(0.1,1.0))\n",
    "\n",
    "t0 = time.time()\n",
    "estimator.batch_estimate(sim, vsf_est, [dataset[i] for i in range(5)], dataset_config, {sensor.name:TareCalibrator()})\n",
    "t1 = time.time()\n",
    "print(\"Estimation took time\",t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see some statistics about the estimates.  The VSF stiffness values are in the `stiffness` attribute, and it will also have new two features, 'K_std' and 'N_obs', which give the standard deviations of the estimates and the number of frames in which each point has been touched, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['color', 'K_std', 'N_obs']\n",
      "Stiffness min -3.1998344623271615e-20, max 10.731247901916504, mean 0.14467070996761322, std 0.411377489566803\n",
      "Number of points touched 2070/26577\n",
      "Touched stiffness min -3.1998344623271615e-20, max 10.731247901916504, mean 0.6735327839851379, std 1.3672837018966675\n"
     ]
    }
   ],
   "source": [
    "print('Features:',list(vsf_est.features.keys()))\n",
    "stiffness = vsf_est.stiffness.cpu().numpy()\n",
    "N_obs = vsf_est.features['N_obs'].cpu().numpy()\n",
    "touched_mask = N_obs > 0\n",
    "print('Stiffness min {}, max {}, mean {}, std {}'.format(np.min(stiffness),np.max(stiffness),np.average(stiffness),np.std(stiffness)))\n",
    "print('Number of points touched {}/{}'.format(np.sum(N_obs > 0),stiffness.shape[0]))\n",
    "print('Touched stiffness min {}, max {}, mean {}, std {}'.format(np.min(stiffness[touched_mask]),np.max(stiffness[touched_mask]),np.average(stiffness[touched_mask]),np.std(stiffness[touched_mask])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize the estimates. For clearer visualization, we will set the stiffness of the untouched points to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stiffness range:  -3.1998345e-20 10.731248\n",
      "#########################################\n",
      "klampt.vis: Creating dialog on window 9\n",
      "#########################################\n",
      "vis.dialog(): waiting for window 9 on vis thread to complete....\n",
      "vis.dialog(): ... dialog done\n"
     ]
    }
   ],
   "source": [
    "vsf_est.stiffness[~touched_mask] = 0\n",
    "vis.debug(world=world.world, estimated_pc = vsf_to_point_cloud(vsf_est), origin = view.origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's check the accuracy of the predictions on the 5-sequence training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 0 joint torque RMSEs [0.65597066 3.56731717 1.10205706 1.93419589 0.84548271 0.3813909\n",
      " 0.148807  ]\n",
      "Sequence 1 joint torque RMSEs [2.09448144 1.14818954 1.24078013 1.01514761 0.67603356 0.36889048\n",
      " 0.26586546]\n",
      "Sequence 2 joint torque RMSEs [3.33935766 0.61217771 1.31126004 0.93945916 0.27872824 0.18159706\n",
      " 0.28477131]\n",
      "Sequence 3 joint torque RMSEs [1.9271775  0.64566873 1.4919207  0.84887023 0.38229206 0.75245997\n",
      " 0.0639786 ]\n",
      "Sequence 4 joint torque RMSEs [0.30714597 0.62065842 0.25630812 0.78157091 0.10857327 0.48224374\n",
      " 0.10941095]\n"
     ]
    }
   ],
   "source": [
    "for seqno in range(len(dataset)):\n",
    "    #extract the sequence of controls and observations.  This is boilerplate\n",
    "    seq = dataset[seqno]\n",
    "    control_seq = []\n",
    "    sensor_seq = []\n",
    "    for frame in seq:\n",
    "        control_seq.append({k:frame[v] for k,v in dataset_config.control_keys.items()})\n",
    "        sensor_seq.append({k:frame[v] for k,v in dataset_config.sensor_keys.items()})\n",
    "        \n",
    "    #run the calibration\n",
    "    sim.reset()\n",
    "    n = calibrator.calibrate(sensor,sim,control_seq,sensor_seq)\n",
    "\n",
    "    #now, run the simulator and compare the predicted torques to the actual torques\n",
    "    dt = 0.1  # a guessed time step.  There's no time-dependent functionality in the quasistatic simulator, so this doesn't matter\n",
    "    diffs = []\n",
    "    for frameno in range(n,len(seq)):\n",
    "        sim.step(control_seq[frameno],dt)\n",
    "        pred = sim.measurements()['kinova_joint_torques'].numpy()\n",
    "        actual = sensor_seq[frameno]['kinova_joint_torques']\n",
    "        assert len(pred) == len(actual)\n",
    "        diffs.append(pred-actual)\n",
    "    diffs = np.array(diffs)\n",
    "    print(\"Sequence\",seqno,\"joint torque RMSEs\",np.sqrt(np.mean(diffs**2,axis=0)))\n",
    "\n",
    "    if seqno >= 4: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since comparisons are done frequently, we also have standard functions for calculating these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 0 joint torque RMSEs [0.69780016 3.84516329 1.61585165 2.01967389 1.23613667 0.8431708\n",
      " 0.25137202]\n",
      "Sequence 1 joint torque RMSEs [2.20845026 1.00239434 1.20029741 1.14892304 0.6970521  0.60164085\n",
      " 0.39099949]\n",
      "Sequence 2 joint torque RMSEs [3.47797904 0.68699538 1.53716045 1.22286451 0.61877105 0.44399902\n",
      " 0.16159432]\n",
      "Sequence 3 joint torque RMSEs [1.89585819 0.66626561 1.15412607 0.78892602 0.14895561 0.23488888\n",
      " 0.16254136]\n",
      "Sequence 4 joint torque RMSEs [0.33031763 1.28129661 0.59709474 0.92900601 0.42794409 0.0803795\n",
      " 0.17714087]\n",
      "Original RMSE train 2.4999126840715498\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704083931\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704083986\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704084035\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704084077\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704084113\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704084155\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704084218\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704084271\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704084316\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704084378\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704084443\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704084485\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704084522\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704084581\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704084644\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704084688\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704084753\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704084797\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704084868\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704084930\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704084970\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704085016\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704085061\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704085107\n",
      "Loading sequence ../demo_data/datasets/rubber_fig_tall_angle00/split1/seq_1704085148\n",
      "Original RMSE test 1.0636704276632032\n",
      "Estimated RMSE train 1.5874785032631056\n",
      "Estimated RMSE test 1.8301458743005254\n"
     ]
    }
   ],
   "source": [
    "from vsf.sim.metrics import rmse_sensors\n",
    "calibrators = {'kinova_joint_torques':calibrator}\n",
    "rmses = rmse_sensors(sim,[dataset[i] for i in range(5)],dataset_config,calibrators)\n",
    "for i in range(5):\n",
    "    print(\"Sequence\",i,\"joint torque RMSEs\",rmses['kinova_joint_torques'][i])\n",
    "sim.vsf_objects['vsf'].vsf_model = vsf_empty\n",
    "print(\"Original RMSE train\",rmse_sensors(sim,[dataset[i] for i in range(5)],dataset_config,calibrators,aggregate_seqs=True,aggregate_channels=True)['kinova_joint_torques'])\n",
    "print(\"Original RMSE test\",rmse_sensors(sim,[dataset[i] for i in range(5,30)],dataset_config,calibrators,aggregate_seqs=True,aggregate_channels=True)['kinova_joint_torques'])\n",
    "sim.vsf_objects['vsf'].vsf_model = vsf_est\n",
    "print(\"Estimated RMSE train\",rmse_sensors(sim,[dataset[i] for i in range(5)],dataset_config,calibrators,aggregate_seqs=True,aggregate_channels=True)['kinova_joint_torques'])\n",
    "print(\"Estimated RMSE test\",rmse_sensors(sim,[dataset[i] for i in range(5,30)],dataset_config,calibrators,aggregate_seqs=True,aggregate_channels=True)['kinova_joint_torques'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that we've done a much better job of estimating the RMSEs on the training set but we haven't really improved the testing RMSEs very much.  This is because we've only used 5 sequences for training, and they may have not done a good job of covering the object.  This is a typical issue with using touch data alone.  Read on to the next section to explore better ways of extrapolating using vision features and priors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrapolating VSF data by color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section provides a basic demonstration of learning a color-conditioned stiffness prior.\n",
    "We use a simple algorithm that naively regresses the estimated VSF stiffness using stochastic gradient descent.\n",
    "For more advanced and accurate prior learning, please refer to the Bayesian meta-learning function in estimator module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from vsf.prior.conditional_distribution import LinearGaussianPriorConfig, LinearGaussianPrior\n",
    "from vsf.prior.prior_factory import LearnableVSFPriorFactory\n",
    "\n",
    "linear_gaussian_condig = LinearGaussianPriorConfig(c_dim=3, diag=True, non_neg=True)\n",
    "\n",
    "# setup a simple meta-prior using linear Gaussian with RGB as input features\n",
    "prior_factory = LearnableVSFPriorFactory(['color'], LinearGaussianPrior(linear_gaussian_condig))\n",
    "\n",
    "# TODO: point vsf does not have consistent dtype, need manually convert to float\n",
    "vsf_est.features['color'] = vsf_est.features['color'].float()\n",
    "\n",
    "prior_factory.meta_learn(vsfs=[vsf_est], features=[{'color':vsf_est.features['color'].float()}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating simulation cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/motion/openvsf/demos/../vsf/sensor/base_calibrator.py:78: UserWarning: Contact happens at the first sample, please check the command sequence\n",
      "  warnings.warn('Contact happens at the first sample, please check the command sequence')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations: 5\n",
      "Observed indices: 2070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/motion/miniconda3/envs/vsf/lib/python3.10/site-packages/cvxpy/problems/problem.py:158: UserWarning: Objective contains too many subexpressions. Consider vectorizing your CVXPY code to speed up compilation.\n",
      "  warnings.warn(\"Objective contains too many subexpressions. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuadProgOptimizer: start solving cvxpy problem...\n",
      "QuadProgOptimizer: cvxpy solve time = 6.372997045516968\n",
      "Estimation took time 12.989048957824707\n"
     ]
    }
   ],
   "source": [
    "# Now create an estimator using the learned prior\n",
    "estimator = PointVSFEstimator(PointVSFEstimatorConfig(), prior_factory)\n",
    "\n",
    "t0 = time.time()\n",
    "estimator.batch_estimate(sim, vsf_est, [dataset[i] for i in range(5)], dataset_config, {sensor.name:TareCalibrator()})\n",
    "t1 = time.time()\n",
    "print(\"Estimation took time\",t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting voxel grid resolution 0.003220559224726908\n",
      "vsf_show: Using the following stiffness values: [0.010435911826789379, 0.03983685374259949, 0.06923779100179672, 0.09863872826099396, 0.1280396729707718]\n",
      "klampt.vis: auto-fitting camera to scene.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized OpenGL version\n",
      "Unrecognized OpenGL version\n"
     ]
    }
   ],
   "source": [
    "# show results with color prior, we expect to see a larger high stiffness region \n",
    "vsf_show(vsf_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating VSFs for Moving Objects\n",
    "\n",
    "PointVSF also supports estimation when the object is moving.\n",
    "\n",
    "We assume the presence of an external tracking module that estimates the current rigid transformation of the VSF object. The only difference in this setting is that, when applying control to the object, an additional key `{vsf_object_name}_state` must be provided. This key represents the homogeneous transformation of the object as a 4x4 matrix. The simulator will internally update the rigid transformation of the VSF object before running the simulation.\n",
    "\n",
    "To estimate a movable VSF, load the `brown_boot_moving` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load empty vsf model for moving brown boot\n",
    "from vsf import vsf_from_file\n",
    "moving_vsf_empty = vsf_from_file('../demo_data/saved_vsfs/brown_boot_moving/vsf_empty.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stiffness range:  0.0 0.0\n",
      "#########################################\n",
      "klampt.vis: Creating dialog on window 10\n",
      "#########################################\n",
      "vis.dialog(): waiting for window 10 on vis thread to complete....\n",
      "vis.dialog(): ... dialog done\n"
     ]
    }
   ],
   "source": [
    "# Show the processed VSF model\n",
    "from vsf.visualize.klampt_visualization import vsf_to_point_cloud\n",
    "vis.debug(empty_pc = vsf_to_point_cloud(moving_vsf_empty, masked_view_fraction=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the simulator for a movable VSF object. This setup is identical to creating a standard simulation environment, except for the control keys used to manipulate the object, which will be introduced in the next section on dataset setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorldModel::LoadRobot: ../knowledge/robot_model/kinova_gen3.urdf\n",
      "URDFParser: Link size: 9\n",
      "URDFParser: Joint size: 9\n",
      "TriMeshTopology: mesh has 7 triangles with duplicate neighbors!\n",
      "  Triangle range 2410 to 2722\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 7 triangles with duplicate neighbors!\n",
      "  Triangle range 2410 to 2722\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 22 triangles with duplicate neighbors!\n",
      "  Triangle range 1990 to 3298\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 22 triangles with duplicate neighbors!\n",
      "  Triangle range 1990 to 3298\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 18 triangles with duplicate neighbors!\n",
      "  Triangle range 4061 to 4257\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 18 triangles with duplicate neighbors!\n",
      "  Triangle range 4061 to 4257\n",
      "  May see strange results for some triangle mesh operations\n",
      "URDFParser: Done loading robot file ../knowledge/robot_model/kinova_gen3.urdf\n",
      "Warning: model EndEffector_Link type  is not triangle mesh\n",
      "FMM_Fill identifies 1305 surface, 731 interior, 2003 exterior cells\n",
      "FMM starting with 835 surface cells, grid of size 13 13 21\n",
      "FMM found 1151 interior and 2398 exterior cells\n",
      "FMM_Fill identifies 1076 surface, 539 interior, 1737 exterior cells\n",
      "FMM starting with 684 surface cells, grid of size 13 13 21\n",
      "FMM found 867 interior and 2682 exterior cells\n",
      "FMM_Fill identifies 1503 surface, 788 interior, 2376 exterior cells\n",
      "FMM starting with 829 surface cells, grid of size 13 31 13\n",
      "FMM found 1113 interior and 4126 exterior cells\n",
      "FMM_Fill identifies 1358 surface, 699 interior, 2167 exterior cells\n",
      "FMM starting with 781 surface cells, grid of size 13 13 28\n",
      "FMM found 1077 interior and 3655 exterior cells\n",
      "FMM_Fill identifies 1122 surface, 526 interior, 1868 exterior cells\n",
      "FMM starting with 686 surface cells, grid of size 13 30 12\n",
      "FMM found 821 interior and 3859 exterior cells\n",
      "FMM_Fill identifies 522 surface, 210 interior, 930 exterior cells\n",
      "FMM starting with 472 surface cells, grid of size 10 12 17\n",
      "FMM found 442 interior and 1598 exterior cells\n",
      "FMM_Fill identifies 510 surface, 190 interior, 932 exterior cells\n",
      "FMM starting with 484 surface cells, grid of size 10 19 12\n",
      "FMM found 396 interior and 1884 exterior cells\n",
      "FMM_Fill identifies 290 surface, 100 interior, 548 exterior cells\n",
      "FMM starting with 317 surface cells, grid of size 11 11 10\n",
      "FMM found 254 interior and 956 exterior cells\n",
      "FMM_Fill identifies 226 surface, 65 interior, 453 exterior cells\n",
      "FMM starting with 217 surface cells, grid of size 14 11 9\n",
      "FMM found 128 interior and 1258 exterior cells\n",
      "Geometry: AnyGeometry::Convert: FMM grid bounding box -0.0542777 -0.055 0.0261356   0.0857223 0.055 0.116136\n"
     ]
    }
   ],
   "source": [
    "from vsf.sim import klamptWorldWrapper, QuasistaticVSFSimulator\n",
    "from vsf.sim.point_vsf_body import ContactParams\n",
    "from vsf.sensor.punyo_dense_force_sensor import PunyoDenseForceSensor\n",
    "\n",
    "# create a new world\n",
    "world = klamptWorldWrapper()\n",
    "world.add_robot('kinova','../knowledge/robot_model/kinova_gen3.urdf')\n",
    "robot = world.world.robot(0)\n",
    "\n",
    "# the punyo geometry is added to the end effector link of the robot\n",
    "world.add_geometry_from_file('punyo', '../knowledge/robot_model/punyo_mesh_complete.ply', \n",
    "                             geom_type='deformable', parent_name='EndEffector_Link', \n",
    "                             parent_relative_transform=np.array([[0.0, -1.0, 0.0, 0.0], [0.34202014, 0.0, -0.93969262, 0.02111], \n",
    "                                                                 [0.93969262, 0.0, 0.34202014, 0.096142], [0.0, 0.0, 0.0, 1.0]]))\n",
    "\n",
    "# this preprocessing needs to be done before running the simulator with a point VSF body\n",
    "world.setup_local_pcd_lst('open3d')\n",
    "world.setup_local_sdf_lst()\n",
    "\n",
    "# initialize all sensors to add in the simulator\n",
    "dense_force_sensor = PunyoDenseForceSensor('punyo_force','punyo')\n",
    "\n",
    "# create a simulator with the world, a joint torque sensor, and the vsf body\n",
    "moving_sim = QuasistaticVSFSimulator(world, [dense_force_sensor])\n",
    "vsf_body = moving_sim.add_deformable('vsf', moving_vsf_empty, contact_params=None)  #if you want to customize how the VSF is simulated, you can pass in a ContactParams object here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Up the Dataset with a Moving Object\n",
    "\n",
    "Since we use the `PunyoDenseForceSensor`, we obtain the deformed vertex locations as `punyo_state` and the per-vertex contact forces as `punyo_force`.\n",
    "The `vsf_state` represents the homogeneous rigid transformation of the VSF object, which is obtained from an external tracking algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 90 sequences\n"
     ]
    }
   ],
   "source": [
    "from vsf.dataset.constructors import DatasetConfig, dataset_from_config\n",
    "\n",
    "keys = {'kinova_state': 7, \n",
    "        'punyo_state': [[390, 3], np.ndarray], \n",
    "        'punyo_force': [[390, 3], np.ndarray], \n",
    "        'vsf_state': [[4, 4], np.ndarray]}  # vsf_state is rigid transformation of VSF object\n",
    "dataset_config = DatasetConfig(type='moving_dataset', \n",
    "                               path='../demo_data/datasets/brown_boot_moving', keys=keys)\n",
    "dataset = dataset_from_config(dataset_config)\n",
    "print(\"Dataset has {} sequences\".format(len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we visualize the collected  dataset with estimated tracked object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from klampt.math import se3\n",
    "from klampt import vis\n",
    "vis.init('PyQt')  #needed inside Jupyter Notebook to show an OpenGL window\n",
    "vis.scene().clear()\n",
    "vis.add(\"world\", world.world)\n",
    "\n",
    "\n",
    "# add table\n",
    "# the table are for visualization only, not added to the simulator to avoid extra computation in the simulation\n",
    "from klampt.model.create import box\n",
    "b1 = box(1.,1.5,1.1,center=(0.25,0,-0.55),type='GeometricPrimitive')\n",
    "vis.add(\"table\", b1, hide_label=True)\n",
    "b2 = box(0.7,0.45,0.12,center=(0.3,0.4,0),type='GeometricPrimitive')\n",
    "vis.add(\"box\", b2, hide_label=True)\n",
    "\n",
    "# add triangle mesh of the moving brown boot to visualize tracked transformations\n",
    "boot_mesh = Geometry3D()\n",
    "boot_mesh.loadFile('../demo_data/datasets/brown_boot_moving/object/mesh.obj')\n",
    "\n",
    "vis.add(\"boot_mesh\", boot_mesh)\n",
    "vis.show()\n",
    "\n",
    "import time\n",
    "for i in range(len(dataset)):\n",
    "    seq = dataset[i]\n",
    "    for frame in seq:\n",
    "        control = {}\n",
    "        control['kinova'] = frame['kinova_state']\n",
    "        control['punyo'] = frame['punyo_state']\n",
    "\n",
    "        # step simulation\n",
    "        vis.lock()\n",
    "        moving_sim.step(control, 0.1)\n",
    "        boot_mesh.setCurrentTransform(*se3.from_ndarray(frame['vsf_state'])) # object mesh is for visualization only, so not added to the simulator\n",
    "        vis.unlock()\n",
    "\n",
    "        time.sleep(2/len(seq)) # visualize each sequence for 2 second\n",
    "\n",
    "    moving_sim.reset()\n",
    "    if i >= 5:\n",
    "        break\n",
    "vis.clear()\n",
    "vis.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Point VSF estimation on a moving object. Since we use the Punyo Dense Force Sensor, the estimation may take longer.\n",
    "\n",
    "In this example, we run the estimation on a single touch sequence to demonstrate that the estimation code remains the same as in the previous pipeline with a fixed VSF object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sequence ../demo_data/datasets/brown_boot_moving/seq_000\n",
      "Generating simulation cache\n",
      "Number of observations: 1\n",
      "Observed indices: 43837\n",
      "QuadProgOptimizer: start solving cvxpy problem...\n",
      "QuadProgOptimizer: cvxpy solve time = 30.95504140853882\n",
      "Estimation took time 51.40388250350952\n"
     ]
    }
   ],
   "source": [
    "from vsf.sensor import TareCalibrator\n",
    "from vsf.estimator.point_vsf_estimator import PointVSFEstimator, PointVSFEstimatorConfig\n",
    "from vsf.prior.prior_factory import GaussianVSFPriorFactory\n",
    "import time\n",
    "import copy\n",
    "moving_vsf_est = moving_vsf_empty\n",
    "moving_vsf_empty = copy.deepcopy(moving_vsf_est)  #save a copy of the uninitialized VSF for later\n",
    "\n",
    "#the second argument sets the prior estimate to a mean of 0.5 and a standard deviation of 1.0\n",
    "estimator = PointVSFEstimator(PointVSFEstimatorConfig(), GaussianVSFPriorFactory(0.0,1.0))\n",
    "\n",
    "t0 = time.time()\n",
    "estimator.batch_estimate(moving_sim, moving_vsf_est, [dataset[i] for i in range(1)], dataset_config)\n",
    "t1 = time.time()\n",
    "print(\"Estimation took time\",t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting voxel grid resolution 0.0019416289327088357\n",
      "vsf_show: Using the following stiffness values: [2.5153495695619623e-16, 0.0007477474282495677, 0.0014954948564991355, 0.0022432422265410423, 0.002990989712998271]\n",
      "klampt.vis: auto-fitting camera to scene.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized OpenGL version\n",
      "Unrecognized OpenGL version\n"
     ]
    }
   ],
   "source": [
    "# visualize estimated vsf\n",
    "# point VSF estimation with Punyo dense force sensor suffer from resolution limitation\n",
    "# please refer to the neural_vsf_playground notebook for better estimation with neural VSF\n",
    "vsf_show(moving_vsf_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-sensor estimation\n",
    "\n",
    "The estimation techniques above can work for any number of sensors.  Simply create more sensors to add to the simulator, and set up the observations dictionary to the estimator appropriately.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vsf import vsf_from_file\n",
    "shoe_vsf_empty = vsf_from_file('../demo_data/saved_vsfs/white_nike_fixed/vsf_empty.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stiffness range:  0.0 0.0\n",
      "#########################################\n",
      "klampt.vis: Creating dialog on window 11\n",
      "#########################################\n",
      "vis.dialog(): waiting for window 11 on vis thread to complete....\n",
      "vis.dialog(): ... dialog done\n"
     ]
    }
   ],
   "source": [
    "# Show the processed VSF model\n",
    "from vsf.visualize.klampt_visualization import vsf_to_point_cloud\n",
    "vis.debug(empty_pc = vsf_to_point_cloud(shoe_vsf_empty, masked_view_fraction=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we add a joint torque sensor and a Punyo pressure sensor to the simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorldModel::LoadRobot: ../knowledge/robot_model/kinova_gen3.urdf\n",
      "URDFParser: Link size: 9\n",
      "URDFParser: Joint size: 9\n",
      "URDFParser: Done loading robot file ../knowledge/robot_model/kinova_gen3.urdf\n",
      "Warning: model EndEffector_Link type  is not triangle mesh\n",
      "FMM_Fill identifies 1305 surface, 731 interior, 2003 exterior cells\n",
      "FMM starting with 835 surface cells, grid of size 13 13 21\n",
      "FMM found 1151 interior and 2398 exterior cells\n",
      "FMM_Fill identifies 1076 surface, 539 interior, 1737 exterior cells\n",
      "FMM starting with 684 surface cells, grid of size 13 13 21\n",
      "FMM found 867 interior and 2682 exterior cells\n",
      "FMM_Fill identifies 1503 surface, 788 interior, 2376 exterior cells\n",
      "FMM starting with 829 surface cells, grid of size 13 31 13\n",
      "FMM found 1113 interior and 4126 exterior cells\n",
      "FMM_Fill identifies 1358 surface, 699 interior, 2167 exterior cells\n",
      "FMM starting with 781 surface cells, grid of size 13 13 28\n",
      "FMM found 1077 interior and 3655 exterior cells\n",
      "FMM_Fill identifies 1122 surface, 526 interior, 1868 exterior cells\n",
      "FMM starting with 686 surface cells, grid of size 13 30 12\n",
      "FMM found 821 interior and 3859 exterior cells\n",
      "FMM_Fill identifies 522 surface, 210 interior, 930 exterior cells\n",
      "FMM starting with 472 surface cells, grid of size 10 12 17\n",
      "FMM found 442 interior and 1598 exterior cells\n",
      "FMM_Fill identifies 510 surface, 190 interior, 932 exterior cells\n",
      "FMM starting with 484 surface cells, grid of size 10 19 12\n",
      "FMM found 396 interior and 1884 exterior cells\n",
      "FMM_Fill identifies 290 surface, 100 interior, 548 exterior cells\n",
      "FMM starting with 317 surface cells, grid of size 11 11 10\n",
      "FMM found 254 interior and 956 exterior cells\n",
      "FMM_Fill identifies 226 surface, 65 interior, 453 exterior cells\n",
      "FMM starting with 217 surface cells, grid of size 14 11 9\n",
      "FMM found 128 interior and 1258 exterior cells\n",
      "Geometry: AnyGeometry::Convert: FMM grid bounding box -0.0542777 -0.055 0.0261356   0.0857223 0.055 0.116136\n"
     ]
    }
   ],
   "source": [
    "from vsf.sim import klamptWorldWrapper, QuasistaticVSFSimulator\n",
    "from vsf.sim.point_vsf_body import ContactParams\n",
    "from vsf.sensor.joint_torque_sensor import JointTorqueSensor\n",
    "from vsf.sensor.punyo_pressure_sensor import PunyoPressureSensor\n",
    "\n",
    "# create a new world\n",
    "world = klamptWorldWrapper()\n",
    "world.add_robot('kinova','../knowledge/robot_model/kinova_gen3.urdf')\n",
    "robot = world.world.robot(0)\n",
    "\n",
    "# the punyo geometry is added to the end effector link of the robot\n",
    "world.add_geometry_from_file('punyo', '../knowledge/robot_model/punyo_mesh_complete.ply', \n",
    "                             geom_type='deformable', parent_name='EndEffector_Link', \n",
    "                             parent_relative_transform=np.array([[0.0, -1.0, 0.0, 0.0], \n",
    "                                                                 [-0.05582150, 0.0, -0.9984407, 0.02111], \n",
    "                                                                 [0.99844076, 0.0, -0.0558215, 0.096142], \n",
    "                                                                 [0.0, 0.0, 0.0, 1.0]]))\n",
    "\n",
    "# this preprocessing needs to be done before running the simulator with a point VSF body\n",
    "world.setup_local_pcd_lst('open3d')\n",
    "world.setup_local_sdf_lst()\n",
    "\n",
    "# initialize all sensors to add in the simulator\n",
    "joint_torque_sensor = JointTorqueSensor('kinova_joint_torques','kinova',[robot.link(i).name for i in range(1,8)])\n",
    "pressure_sensor = PunyoPressureSensor('punyo_pressure','punyo')\n",
    "\n",
    "# create a simulator with the world, a joint torque sensor, and the vsf body\n",
    "shoe_sim = QuasistaticVSFSimulator(world, [joint_torque_sensor, pressure_sensor])\n",
    "vsf_body = shoe_sim.add_deformable('vsf', shoe_vsf_empty, contact_params=None)  #if you want to customize how the VSF is simulated, you can pass in a ContactParams object here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the dataset for multiple sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 181 sequences\n"
     ]
    }
   ],
   "source": [
    "from vsf.dataset.constructors import DatasetConfig, dataset_from_config\n",
    "\n",
    "keys = {'kinova_joint_torques': 7, 'kinova_state': 7, 'punyo_pressure': 1}  #describes the keys present in the dataset\n",
    "dataset_config = DatasetConfig(type='multi_sensor_dataset', \n",
    "                               path='../demo_data/datasets/white_nike_fixed', keys=keys)\n",
    "dataset = dataset_from_config(dataset_config)\n",
    "print(\"Dataset has {} sequences\".format(len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the estimation code is basically the same, the only difference is that we need to provide each sensor a corresponding calibrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sequence ../demo_data/datasets/white_nike_fixed/seq_000\n",
      "Loading sequence ../demo_data/datasets/white_nike_fixed/seq_001\n",
      "Loading sequence ../demo_data/datasets/white_nike_fixed/seq_002\n",
      "Loading sequence ../demo_data/datasets/white_nike_fixed/seq_003\n",
      "Loading sequence ../demo_data/datasets/white_nike_fixed/seq_004\n",
      "Generating simulation cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/motion/openvsf/demos/../vsf/sensor/base_calibrator.py:78: UserWarning: Contact happens at the first sample, please check the command sequence\n",
      "  warnings.warn('Contact happens at the first sample, please check the command sequence')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations: 5\n",
      "Observed indices: 2311\n",
      "QuadProgOptimizer: start solving cvxpy problem...\n",
      "QuadProgOptimizer: cvxpy solve time = 0.6255617141723633\n",
      "Estimation took time 1.2020339965820312\n"
     ]
    }
   ],
   "source": [
    "from vsf.sensor import TareCalibrator\n",
    "from vsf.estimator.point_vsf_estimator import PointVSFEstimator, PointVSFEstimatorConfig\n",
    "from vsf.prior.prior_factory import GaussianVSFPriorFactory\n",
    "import time\n",
    "import copy\n",
    "shoe_vsf_est = shoe_vsf_empty\n",
    "shoe_vsf_empty = copy.deepcopy(shoe_vsf_est)  #save a copy of the uninitialized VSF for later\n",
    "\n",
    "#the second argument sets the prior estimate to a mean of 0.5 and a standard deviation of 1.0\n",
    "estimator = PointVSFEstimator(PointVSFEstimatorConfig(), GaussianVSFPriorFactory(0.0,1.0))\n",
    "\n",
    "calibrators = {'kinova_joint_torques':TareCalibrator(), 'punyo_pressure':TareCalibrator()}\n",
    "\n",
    "t0 = time.time()\n",
    "estimator.batch_estimate(shoe_sim, shoe_vsf_est, [dataset[i] for i in range(5)], dataset_config, calibrators)\n",
    "t1 = time.time()\n",
    "print(\"Estimation took time\",t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting voxel grid resolution 0.008660254037844345\n",
      "vsf_show: Using the following stiffness values: [8.399690833170389e-20, 0.03892963379621506, 0.07785926759243011, 0.11678890138864517, 0.15571853518486023]\n",
      "klampt.vis: auto-fitting camera to scene.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized OpenGL version\n",
      "Unrecognized OpenGL version\n"
     ]
    }
   ],
   "source": [
    "# visualize estimated vsf\n",
    "vsf_show(shoe_vsf_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 0 joint torque RMSEs [3.08475313 4.34439077 2.97743361 2.10242783 0.25027262 2.40612587\n",
      " 0.18195641]\n",
      "Sequence 0 punyo pressure RMSEs [0.07472547]\n",
      "Sequence 1 joint torque RMSEs [2.78579017 3.79814828 1.98058953 4.54617965 0.31258196 2.55038131\n",
      " 0.32657833]\n",
      "Sequence 1 punyo pressure RMSEs [0.1162529]\n",
      "Sequence 2 joint torque RMSEs [2.16866864 5.07206635 1.90121116 3.20353391 0.41221836 2.59197523\n",
      " 0.20635116]\n",
      "Sequence 2 punyo pressure RMSEs [0.0791336]\n",
      "Sequence 3 joint torque RMSEs [1.68484687 4.30863297 0.88164929 6.09108716 0.09132125 2.9835171\n",
      " 0.35279591]\n",
      "Sequence 3 punyo pressure RMSEs [0.14270338]\n",
      "Sequence 4 joint torque RMSEs [3.23590293 5.74930225 2.10608991 7.87075234 0.25791414 4.08796978\n",
      " 0.10874685]\n",
      "Sequence 4 punyo pressure RMSEs [0.27086107]\n"
     ]
    }
   ],
   "source": [
    "from vsf.utils.data_utils import remap_dict_in_seq\n",
    "\n",
    "for seqno in range(len(dataset)):\n",
    "    #extract the sequence of controls and observations.  This is boilerplate\n",
    "    seq = dataset[seqno]\n",
    "    \n",
    "    control_seq, sensor_seq = remap_dict_in_seq(seq, shoe_sim.get_control_keys(), shoe_sim.get_sensor_keys())\n",
    "        \n",
    "    #run the calibration\n",
    "    shoe_sim.reset()\n",
    "    n = max(calibrators['kinova_joint_torques'].calibrate(joint_torque_sensor,shoe_sim,control_seq,sensor_seq), \n",
    "            calibrators['punyo_pressure'].calibrate(pressure_sensor,shoe_sim,control_seq,sensor_seq))\n",
    "\n",
    "    #now, run the simulator and compare the predicted torques to the actual torques\n",
    "    dt = 0.1  # a guessed time step.  There's no time-dependent functionality in the quasistatic simulator, so this doesn't matter\n",
    "    joint_torque_diffs = []\n",
    "    punyo_pressure_diffs = []\n",
    "    for frameno in range(n,len(seq)):\n",
    "        shoe_sim.step(control_seq[frameno],dt)\n",
    "        joint_torque_pred = shoe_sim.measurements()['kinova_joint_torques'].numpy()\n",
    "        joint_torque_actual = sensor_seq[frameno]['kinova_joint_torques']\n",
    "        assert len(joint_torque_pred) == len(joint_torque_actual)\n",
    "        joint_torque_diffs.append(joint_torque_pred-joint_torque_actual)\n",
    "        \n",
    "        punyo_pressure_pred = shoe_sim.measurements()['punyo_pressure'].numpy()\n",
    "        punyo_pressure_actual = sensor_seq[frameno]['punyo_pressure']\n",
    "        assert len(punyo_pressure_pred) == len(punyo_pressure_actual)\n",
    "        punyo_pressure_diffs.append(punyo_pressure_pred-punyo_pressure_actual)\n",
    "\n",
    "    joint_torque_diffs = np.array(joint_torque_diffs)\n",
    "    print(\"Sequence\",seqno,\"joint torque RMSEs\",np.sqrt(np.mean(joint_torque_diffs**2,axis=0)))\n",
    "    \n",
    "    punyo_pressure_diffs = np.array(punyo_pressure_diffs)\n",
    "    print(\"Sequence\",seqno,\"punyo pressure RMSEs\",np.sqrt(np.mean(punyo_pressure_diffs**2,axis=0)))\n",
    "\n",
    "    if seqno >= 4: break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vsf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
