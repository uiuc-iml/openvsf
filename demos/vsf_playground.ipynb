{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volumetric Stiffness Field Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "***  klampt.vis: using Qt6 as the visualization backend  ***\n"
     ]
    }
   ],
   "source": [
    "# Auto reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#if you haven't installed vsf and just want to run this from the current directory, uncomment the following lines\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from vsf import vsf_from_file\n",
    "from klampt.io import open3d_convert\n",
    "from klampt import vis, Geometry3D, WorldModel\n",
    "from vsf.visualize.klampt_visualization import vsf_show\n",
    "\n",
    "vis.init('PyQt')  #needed to pop up Klampt OpenGL windows in Jupyter notebook\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data from box\n",
    "\n",
    "+ #### Download single test case: \n",
    "    + Demo data: https://uofi.box.com/s/31wozq63qgqvg8012r1jdfj5mdchmmfp\n",
    "\n",
    "+ #### Download the full dataset\n",
    "    + Download objects assets: https://uofi.box.com/s/2wj11zze45nj2owwqdpm7tsh0keleedw\n",
    "    + Download estimates VSF models for simulation: https://uofi.box.com/s/g1i02pxf4quk0zt7nzv4qhovlhfnt3bl\n",
    "    + Download raw visual-tactile dataset: https://uofi.box.com/s/grqsjh5m27jkin14t097pvjvy9b1bk6r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a VSF from file\n",
    "\n",
    "In this example we will load one of the demo objects.  Let's assume that you have placed `demo_data` in the parent directory of this Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "vsf_model = vsf_from_file('../demo_data/est_rubber_fig_tall_angle00/final_est')\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the loaded model.  We can do so in Open3D using a point cloud visualization, or in Klampt with a point cloud or implicit surface visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stiffness range:  -2.4917295937509232e-17 106.25068228144467\n"
     ]
    }
   ],
   "source": [
    "# Visualize VSF point cloud in Open3D\n",
    "import open3d as o3d\n",
    "from vsf.visualize.o3d_visualization import vsf_to_point_cloud\n",
    "vis_pcd = vsf_to_point_cloud(vsf_model)\n",
    "o3d.visualization.draw_geometries([vis_pcd], window_name='VSF vis_pcd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stiffness range:  -2.4917295937509232e-17 106.25068228144467\n",
      "################################################################\n",
      "klampt.vis: Running multi-threaded dialog, waiting to complete...\n",
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Dialog on window 1 starting\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWidget.initialize: no action menu?\n",
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: QApplication was not created in the main() thread.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################\n",
      "klampt.vis: Dialog done on window 1 result 1\n",
      "#########################################\n",
      "klampt.vis: ... dialog done, leaving thread open\n",
      "################################################################\n",
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Making window 0\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n",
      "#########################################\n",
      "klampt.vis: Window 0 close\n",
      "#########################################\n",
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Dialog on window 2 starting\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWidget.initialize: no action menu?\n",
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n",
      "#########################################\n",
      "klampt.vis: Dialog done on window 2 result 0\n",
      "#########################################\n",
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Dialog on window 3 starting\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWidget.initialize: no action menu?\n",
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n",
      "#########################################\n",
      "klampt.vis: Dialog done on window 3 result 0\n",
      "#########################################\n",
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Dialog on window 4 starting\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWidget.initialize: no action menu?\n",
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n",
      "#########################################\n",
      "klampt.vis: Dialog done on window 4 result 1\n",
      "#########################################\n",
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Dialog on window 5 starting\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWidget.initialize: no action menu?\n",
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n",
      "#########################################\n",
      "klampt.vis: Dialog done on window 5 result 1\n",
      "#########################################\n",
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Dialog on window 6 starting\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWidget.initialize: no action menu?\n",
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n",
      "#########################################\n",
      "klampt.vis: Dialog done on window 6 result 1\n",
      "#########################################\n",
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Dialog on window 7 starting\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWidget.initialize: no action menu?\n",
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n",
      "#########################################\n",
      "klampt.vis: Dialog done on window 7 result 1\n",
      "#########################################\n",
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Dialog on window 8 starting\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWidget.initialize: no action menu?\n",
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n",
      "#########################################\n",
      "klampt.vis: Dialog done on window 8 result 1\n",
      "#########################################\n",
      "vis: creating GL window\n",
      "######### QtGLWindow setProgram ###############\n",
      "######### QtGLWindow setProgram ###############\n",
      "#########################################\n",
      "klampt.vis: Dialog on window 9 starting\n",
      "#########################################\n",
      "######### QtGLWindow Initialize GL ###############\n",
      "QtGLWidget.initialize: no action menu?\n",
      "QtGLWindow.resizeGL: called when invisible?\n",
      "QtGLWindow.paintGL: called while invisible?\n",
      "#########################################\n",
      "klampt.vis: Dialog done on window 9 result 1\n",
      "#########################################\n"
     ]
    }
   ],
   "source": [
    "# Klampt point cloud visualization of VSF\n",
    "from vsf.visualize.klampt_visualization import vsf_to_point_cloud\n",
    "k_pcd = Geometry3D(vsf_to_point_cloud(vsf_model))\n",
    "vis.debug(k_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting voxel grid resolution 0.020093083968962675\n",
      "klampt.vis: auto-fitting camera to scene.\n"
     ]
    }
   ],
   "source": [
    "# Klampt volumetric visualization of VSF\n",
    "stiffness_levels = [0.27072093, 4.54502328, 8.81932563, 9.09362797, 10.36793032]\n",
    "vsf_show(vsf_model, stiffness_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VSF estimation from tactile data\n",
    "\n",
    "In this example, we will create VSF from a dataset that includes tactile observations.\n",
    "\n",
    "- Create an empty VSF.  We will use a VSFFactory to shape the VSF rest points from an RGBD point cloud\n",
    "- Configure the robot model and sensor(s).  In this case the robot is a Kinova Gen3, and there is only one sensor that provides joint torques.\n",
    "- Load a dataset of trials giving robot actions and observations from sensor(s) \n",
    "- Create an estimator, and run it in batch mode on the dataset.\n",
    "\n",
    "Let's start by creating an empty VSF.  If you have an RGB-D scanned object, you should use a `VSFRGBDCameraFactory` like the following code to construct the VSF points from a region of interest in the point cloud, extending through a volume behind the camera's point of view.  It doesn't really matter how you get the points; you can also create an empty box using the `vsf.vsf_from_box()` function, create a VSF from a 3D scanned mesh using `vsf.vsf_from_mesh()`, or load a previously saved VSF from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBox selection: keeping 129694 points out of 459947\n",
      "downsampling visual point cloud to voxel size 0.02\n",
      "iter step 0 left pts: 129694\n",
      "iter step 1 left pts: 129666\n",
      "iter step 2 left pts: 129567\n",
      "iter step 3 left pts: 129479\n",
      "iter step 4 left pts: 129241\n",
      "iter step 5 left pts: 129014\n",
      "iter step 6 left pts: 128862\n",
      "iter step 7 left pts: 128657\n",
      "iter step 8 left pts: 128345\n",
      "iter step 9 left pts: 128086\n",
      "iter step 10 left pts: 127695\n",
      "iter step 11 left pts: 127290\n",
      "iter step 12 left pts: 126953\n",
      "iter step 13 left pts: 126644\n",
      "iter step 14 left pts: 126349\n",
      "iter step 15 left pts: 126033\n",
      "iter step 16 left pts: 125654\n",
      "iter step 17 left pts: 125288\n",
      "iter step 18 left pts: 124893\n",
      "iter step 19 left pts: 124478\n",
      "iter step 20 left pts: 124064\n",
      "iter step 21 left pts: 123677\n",
      "iter step 22 left pts: 123282\n",
      "iter step 23 left pts: 122795\n",
      "iter step 24 left pts: 121882\n",
      "iter step 25 left pts: 120518\n",
      "iter step 26 left pts: 118863\n",
      "iter step 27 left pts: 117332\n",
      "iter step 28 left pts: 114992\n",
      "iter step 29 left pts: 110272\n",
      "iter step 30 left pts: 101861\n",
      "iter step 31 left pts: 91698\n",
      "iter step 32 left pts: 79514\n",
      "iter step 33 left pts: 66521\n",
      "iter step 34 left pts: 56075\n",
      "iter step 35 left pts: 47921\n",
      "iter step 36 left pts: 40719\n",
      "iter step 37 left pts: 34362\n",
      "iter step 38 left pts: 28862\n",
      "iter step 39 left pts: 24818\n",
      "iter step 40 left pts: 21681\n",
      "iter step 41 left pts: 19139\n",
      "iter step 42 left pts: 16206\n",
      "iter step 43 left pts: 13074\n",
      "iter step 44 left pts: 9662\n",
      "iter step 45 left pts: 6991\n",
      "iter step 46 left pts: 5212\n",
      "iter step 47 left pts: 3747\n",
      "iter step 48 left pts: 2268\n",
      "iter step 49 left pts: 1207\n",
      "number of surface points: 1978\n",
      "number of volume points: 24599\n",
      "farthest points downsampling to 20000 points\n",
      "20000 rest points for VSF model created from RGBD factory\n"
     ]
    }
   ],
   "source": [
    "from vsf.core.vsf_factory import VSFRGBDCameraFactory, VSFRGBDCameraFactoryConfig, ViewConfig\n",
    "\n",
    "view = ViewConfig(origin=[-0.55639158,1.04689234,0.52593784])  # need to set the origin of the camera so that volume points can be created\n",
    "#we will select points within a bounding box \n",
    "config = VSFRGBDCameraFactoryConfig(fps_num=20000, voxel_size=0.02,\n",
    "                                    view = view, bbox = [[-1.03, -0.64, -0.22], [-0.29, 0.23, 0.73]], downsample_visual=True, verbose=True)\n",
    "factory = VSFRGBDCameraFactory(config)\n",
    "#process() does all the work\n",
    "vsf_empty = factory.process('../demo_data/rubber_fig_tall_angle00/bg_pcd.pcd')  #the PCD file is the point cloud of the RGBD scene, including the background \n",
    "print('{} rest points for VSF model created from RGBD factory'.format(len(vsf_empty.rest_points)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stiffness range:  0.0 0.0\n",
      "#########################################\n",
      "klampt.vis: Creating dialog on window 2\n",
      "#########################################\n",
      "vis.dialog(): waiting for window 2 on vis thread to complete....\n",
      "vis.dialog(): ... dialog done\n"
     ]
    }
   ],
   "source": [
    "# Show the processed VSF model\n",
    "from vsf.visualize.klampt_visualization import vsf_to_point_cloud\n",
    "vis.debug(empty_pc = vsf_to_point_cloud(vsf_empty, masked_view_fraction=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a world with a robot, a simulator, and one or more sensors.  This example loads a Kinova Gen3 robot model and uses the joint torque sensors in the simulator.  We also add the empty VSF into the simulator using `sim.add_deformable`.  This creates a body that can be moved through space.  (By default, all VSFs are considered to have a static pose, which works well if the object doesn't move much during interaction.  We will consider moving objects later.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: model EndEffector_Link type  is not triangle mesh\n",
      "WorldModel::LoadRobot: ../knowledge/robot_model/kinova_gen3_repaired.urdf\n",
      "URDFParser: Link size: 9\n",
      "URDFParser: Joint size: 9\n",
      "URDFParser: Done loading robot file ../knowledge/robot_model/kinova_gen3_repaired.urdf\n",
      "FMM_Fill identifies 1305 surface, 731 interior, 2003 exterior cells\n",
      "FMM starting with 835 surface cells, grid of size 13 13 21\n",
      "FMM found 1149 interior and 2400 exterior cells\n",
      "Geometry: AnyGeometry::Convert: FMM grid bounding box -0.0648063 -0.0649216 -0.019575   0.0651937 0.0650784 0.190425\n",
      "FMM_Fill identifies 1076 surface, 539 interior, 1737 exterior cells\n",
      "FMM starting with 684 surface cells, grid of size 13 13 21\n",
      "FMM found 864 interior and 2685 exterior cells\n",
      "Geometry: AnyGeometry::Convert: FMM grid bounding box -0.065 -0.0662972 -0.193375   0.065 0.0637028 0.016625\n",
      "FMM_Fill identifies 1503 surface, 788 interior, 2376 exterior cells\n",
      "FMM starting with 829 surface cells, grid of size 13 31 13\n",
      "FMM found 1113 interior and 4126 exterior cells\n",
      "Geometry: AnyGeometry::Convert: FMM grid bounding box -0.065 -0.2444 -0.0728769   0.065 0.0656 0.0571231\n",
      "TriMeshTopology: mesh has 18 triangles with duplicate neighbors!\n",
      "  Triangle range 2337 to 2722\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 18 triangles with duplicate neighbors!\n",
      "  Triangle range 2337 to 2722\n",
      "  May see strange results for some triangle mesh operations\n",
      "FMM_Fill identifies 1358 surface, 699 interior, 2167 exterior cells\n",
      "FMM starting with 781 surface cells, grid of size 13 13 28\n",
      "FMM found 1079 interior and 3653 exterior cells\n",
      "Geometry: AnyGeometry::Convert: FMM grid bounding box -0.065 -0.0665021 -0.275775   0.065 0.0634979 0.00422499\n",
      "TriMeshTopology: mesh has 74 triangles with duplicate neighbors!\n",
      "  Triangle range 1988 to 3298\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 74 triangles with duplicate neighbors!\n",
      "  Triangle range 1988 to 3298\n",
      "  May see strange results for some triangle mesh operations\n",
      "FMM_Fill identifies 1122 surface, 526 interior, 1868 exterior cells\n",
      "FMM starting with 686 surface cells, grid of size 13 30 12\n",
      "FMM found 820 interior and 3860 exterior cells\n",
      "Geometry: AnyGeometry::Convert: FMM grid bounding box -0.065 -0.23745 -0.0736478   0.065 0.06255 0.0463522\n",
      "FMM_Fill identifies 522 surface, 210 interior, 930 exterior cells\n",
      "FMM starting with 472 surface cells, grid of size 10 12 17\n",
      "FMM found 443 interior and 1597 exterior cells\n",
      "Geometry: AnyGeometry::Convert: FMM grid bounding box -0.0499992 -0.0690232 -0.156752   0.0500008 0.0509768 0.0132482\n",
      "TriMeshTopology: mesh has 37 triangles with duplicate neighbors!\n",
      "  Triangle range 3202 to 4280\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 37 triangles with duplicate neighbors!\n",
      "  Triangle range 3202 to 4280\n",
      "  May see strange results for some triangle mesh operations\n",
      "FMM_Fill identifies 510 surface, 190 interior, 932 exterior cells\n",
      "FMM starting with 484 surface cells, grid of size 10 19 12\n",
      "FMM found 396 interior and 1884 exterior cells\n",
      "Geometry: AnyGeometry::Convert: FMM grid bounding box -0.05 -0.136661 -0.0692511   0.05 0.0533391 0.0507489\n",
      "TriMeshTopology: mesh has 8 triangles with duplicate neighbors!\n",
      "  Triangle range 1850 to 8570\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 8 triangles with duplicate neighbors!\n",
      "  Triangle range 1850 to 8570\n",
      "  May see strange results for some triangle mesh operations\n",
      "FMM_Fill identifies 290 surface, 100 interior, 548 exterior cells\n",
      "FMM starting with 317 surface cells, grid of size 11 11 10\n",
      "FMM found 260 interior and 950 exterior cells\n",
      "Geometry: AnyGeometry::Convert: FMM grid bounding box -0.0550454 -0.055 -0.0834625   0.0549546 0.055 0.0165375\n"
     ]
    }
   ],
   "source": [
    "from vsf.sim import klamptWorldWrapper, QuasistaticVSFSimulator\n",
    "from vsf.sim.point_vsf_body import ContactParams\n",
    "from vsf.sensor.joint_torque_sensor import JointTorqueSensor\n",
    "\n",
    "#create a world\n",
    "world = klamptWorldWrapper()\n",
    "world.add_robot('kinova','../knowledge/robot_model/kinova_gen3_repaired.urdf')\n",
    "robot = world.world.robot(0)\n",
    "\n",
    "#this preprocessing needs to be done before running the simulator with a point VSF body\n",
    "world.setup_local_pcd_lst('open3d')\n",
    "world.setup_local_sdf_lst()\n",
    "\n",
    "#create a simulator with the world, a joint torque sensor, and the vsf body\n",
    "sensor = JointTorqueSensor('kinova_joint_torques','kinova',[robot.link(i).name for i in range(1,8)])\n",
    "sim = QuasistaticVSFSimulator(world, [sensor])\n",
    "vsf_body = sim.add_deformable('vsf',vsf_empty, contact_params=None)  #if you want to customize how the VSF is simulated, you can pass in a ContactParams object here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stiffness range:  0.0 0.0\n",
      "#########################################\n",
      "klampt.vis: Creating dialog on window 3\n",
      "#########################################\n",
      "vis.dialog(): waiting for window 3 on vis thread to complete....\n",
      "TriMeshTopology: mesh has 9 triangles with duplicate neighbors!\n",
      "  Triangle range 273 to 924\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 104 triangles with duplicate neighbors!\n",
      "  Triangle range 3828 to 4274\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 271 triangles with duplicate neighbors!\n",
      "  Triangle range 80 to 3362\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 635 triangles with duplicate neighbors!\n",
      "  Triangle range 29 to 3626\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 587 triangles with duplicate neighbors!\n",
      "  Triangle range 1988 to 3472\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 344 triangles with duplicate neighbors!\n",
      "  Triangle range 4000 to 5015\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 344 triangles with duplicate neighbors!\n",
      "  Triangle range 3199 to 4281\n",
      "  May see strange results for some triangle mesh operations\n",
      "TriMeshTopology: mesh has 378 triangles with duplicate neighbors!\n",
      "  Triangle range 2 to 8834\n",
      "  May see strange results for some triangle mesh operations\n",
      "vis.dialog(): ... dialog done\n"
     ]
    }
   ],
   "source": [
    "# show the world and VSF\n",
    "from vsf.visualize.klampt_visualization import vsf_to_point_cloud\n",
    "vis.debug(world=world.world, empty_pc = vsf_to_point_cloud(vsf_empty), origin = view.origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will set up a dataset. We will load a dataset from a standard folder format, which is configured and loaded automatically in the following example.  We will use a `DatasetConfig` which specifies which keys are present, and which keys used for robot commands and sensor observations.  The `dataset_from_config` function will set up a dataset appropriately to follow the specified configuration.  The standard dataset lazy-loads sequences into memory.\n",
    "\n",
    "More generally, a dataset is any object that can be treated like a list of sequences, and each sequence is a list of dictionaries mapping keys to numpy arrays.  In other words, datasets behave like a `List[List[Dict[str,np.ndarray]]]` type. If you don't want to go through the trouble of saving such a thing to disk, you can just create such an object yourself.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 32 sequences\n"
     ]
    }
   ],
   "source": [
    "from vsf.dataset.constructors import DatasetConfig, dataset_from_config\n",
    "\n",
    "keys = {'torques':7,'angles':7}  #describes the keys present in the dataset\n",
    "dataset_config = DatasetConfig('../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm',\n",
    "                               keys,\n",
    "                               sensor_keys={'kinova_joint_torques':'torques'},\n",
    "                               control_keys={'kinova':'angles'})\n",
    "dataset = dataset_from_config(dataset_config)\n",
    "print(\"Dataset has {} sequences\".format(len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For debugging, let's just validate the trajectories coming from the dataset.  Here we'll show the first 5 trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704083702\n",
      "Stiffness range:  0.0 0.0\n",
      "#########################################\n",
      "klampt.vis: Creating dialog on window 4\n",
      "#########################################\n",
      "vis.dialog(): waiting for window 4 on vis thread to complete....\n",
      "vis.dialog(): ... dialog done\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704083759\n",
      "Stiffness range:  0.0 0.0\n",
      "#########################################\n",
      "klampt.vis: Creating dialog on window 5\n",
      "#########################################\n",
      "vis.dialog(): waiting for window 5 on vis thread to complete....\n",
      "vis.dialog(): ... dialog done\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704083799\n",
      "Stiffness range:  0.0 0.0\n",
      "#########################################\n",
      "klampt.vis: Creating dialog on window 6\n",
      "#########################################\n",
      "vis.dialog(): waiting for window 6 on vis thread to complete....\n",
      "vis.dialog(): ... dialog done\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704083834\n",
      "Stiffness range:  0.0 0.0\n",
      "#########################################\n",
      "klampt.vis: Creating dialog on window 7\n",
      "#########################################\n",
      "vis.dialog(): waiting for window 7 on vis thread to complete....\n",
      "vis.dialog(): ... dialog done\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704083869\n",
      "Stiffness range:  0.0 0.0\n",
      "#########################################\n",
      "klampt.vis: Creating dialog on window 8\n",
      "#########################################\n",
      "vis.dialog(): waiting for window 8 on vis thread to complete....\n",
      "vis.dialog(): ... dialog done\n"
     ]
    }
   ],
   "source": [
    "from klampt.model.trajectory import RobotTrajectory \n",
    "\n",
    "for seqno in range(len(dataset)):\n",
    "    #extract the sequence of commands\n",
    "    seq = dataset[seqno]\n",
    "    commands = []\n",
    "    for frame in range(len(seq)):\n",
    "        frame = seq[frame]\n",
    "        commands.append(frame['angles'])\n",
    "\n",
    "    #convert to a RobotTrajectory and show it\n",
    "    configs = [robot.configFromDrivers(d) for d in commands]\n",
    "    traj = RobotTrajectory(robot,[i/len(configs) for i in range(len(configs))],configs)\n",
    "    vis.debug(robot, {'animation':traj}, 'empty_pc', vsf_to_point_cloud(vsf_empty))\n",
    "    if seqno >= 4: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the discrepancy between the observations and the predicted measurements for a random VSF stiffness.  Here, we're also introducing the notion of sensor calibration, which is usually necessary at the beginning of a trial to tare the values coming from the sensor.\n",
    "\n",
    "A `BaseSensor` can potentially handle its own calibration, but we find it's easier to separate how to calibrate the sensor from the sensor simulator itself.  Here we will generate a `BaseCalibrator` object that we will run at the beginning of each trial to calibrate the sensor.\n",
    "\n",
    "(There is a little bit of work here to convert the dataset keys to the control and sensor keys expected by the simulator, calibrator, and estimators. This boilerplate is used a lot...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 0 calibration: {'tare': array([ 0.45979138, 18.23648429,  0.42123438,  2.86159472,  0.06669243,\n",
      "       -0.8061054 , -0.30282573]), 'gravity_pred_at_tare': array([-1.35915481e-04,  1.91127152e+01,  2.38662322e-01,  2.89546379e+00,\n",
      "        5.89215163e-02, -9.54574667e-01, -7.94720591e-03])}\n",
      "Sequence 0 joint torque RMSEs [9.91913453 3.20994491 4.95261744 1.81149835 0.49278865 0.48767311\n",
      " 0.09661432]\n",
      "Sequence 1 calibration: {'tare': array([ 0.52451001, 19.72127437, -0.08059071,  3.76032879,  0.34009876,\n",
      "       -0.71614274, -0.38496185]), 'gravity_pred_at_tare': array([ 4.59781161e-01,  1.96244829e+01, -3.01500764e-03,  4.47961341e+00,\n",
      "        3.32438221e-01, -7.43565164e-01, -2.97378133e-01])}\n",
      "Sequence 1 joint torque RMSEs [5.87719267 2.9586089  3.12015592 0.66501139 0.89273961 0.58525534\n",
      " 0.26543169]\n",
      "Sequence 2 calibration: {'tare': array([ 0.37255337, 18.40848739,  0.55852668,  3.35344802,  0.42691417,\n",
      "       -0.49719183, -0.20882375]), 'gravity_pred_at_tare': array([ 0.06459304, 19.26186309, -0.12593415,  3.38354258,  0.31101709,\n",
      "       -0.85250602, -0.10024354])}\n",
      "Sequence 2 joint torque RMSEs [4.62330607 0.86450375 1.58638184 0.94171624 0.3244924  0.18021013\n",
      " 0.2845139 ]\n",
      "Sequence 3 calibration: {'tare': array([0., 0., 0., 0., 0., 0., 0.]), 'gravity_pred_at_tare': array([0., 0., 0., 0., 0., 0., 0.])}\n",
      "Sequence 3 joint torque RMSEs [3.74619724 1.41761881 1.67773615 1.11238914 0.31269901 0.45488738\n",
      " 0.20705561]\n",
      "Sequence 4 calibration: {'tare': array([ 0.44969128, 14.27508675, -0.23326894,  5.27838991,  0.40612126,\n",
      "       -0.73751265, -0.04340425]), 'gravity_pred_at_tare': array([-1.06145828e-04,  1.53140507e+01, -6.08667263e-01,  5.93775528e+00,\n",
      "        3.65493894e-02, -9.68525561e-01,  1.07173745e-02])}\n",
      "Sequence 4 joint torque RMSEs [0.59493075 0.58678581 0.60793828 0.75336204 0.10051699 0.15166344\n",
      " 0.23126136]\n"
     ]
    }
   ],
   "source": [
    "from vsf.sensor import TareCalibrator\n",
    "import numpy as np\n",
    "\n",
    "vsf_empty.stiffness.fill_(0.1)  #set a guessed stiffness of the VSF model\n",
    "calibrator = TareCalibrator()\n",
    "for seqno in range(len(dataset)):\n",
    "    #extract the sequence of controls and observations.  This is boilerplate\n",
    "    seq = dataset[seqno]\n",
    "    control_seq = []\n",
    "    sensor_seq = []\n",
    "    for frame in seq:\n",
    "        control_seq.append({k:frame[v] for k,v in dataset_config.control_keys.items()})\n",
    "        sensor_seq.append({k:frame[v] for k,v in dataset_config.sensor_keys.items()})\n",
    "        \n",
    "    #run the calibration\n",
    "    sim.reset()\n",
    "    n = calibrator.calibrate(sensor,sim,control_seq,sensor_seq)\n",
    "    #returns the # of samples used in calibration.  Technically should skip this number of frames for estimation\n",
    "    print(\"Sequence\",seqno,\"calibration:\",sensor.get_calibration())\n",
    "\n",
    "    #now, run the simulator and compare the predicted torques to the actual torques\n",
    "    dt = 0.1  # a guessed time step.  There's no time-dependent functionality in the quasistatic simulator, so this doesn't matter\n",
    "    diffs = []\n",
    "    for frameno in range(n,len(seq)):\n",
    "        sim.step(control_seq[frameno],dt)\n",
    "        pred = sim.measurements()['kinova_joint_torques']\n",
    "        actual = sensor_seq[frameno]['kinova_joint_torques']\n",
    "        assert len(pred) == len(actual)\n",
    "        diffs.append(pred-actual)\n",
    "    diffs = np.array(diffs)\n",
    "    print(\"Sequence\",seqno,\"joint torque RMSEs\",np.sqrt(np.mean(diffs**2,axis=0)))\n",
    "\n",
    "    if seqno >= 4: break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's start the estimation process.  Let's start by using *batch* estimation, which uses all the items in the dataset to estimate the VSF stiffness parameters.  We have to provide a prior to the estimator to initialize its stiffness guess, and we will use a GaussianVSFPriorFactory which assigns an independent Gaussian distribution to each point's stiffness.\n",
    "\n",
    "We can also customize the configuration of the estimator, such as the optimization technique used, but let's not worry about this too much for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating simulation cache\n",
      "Number of observations: 5\n",
      "Observed indices: 1040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/cvxpy/problems/problem.py:158: UserWarning: Objective contains too many subexpressions. Consider vectorizing your CVXPY code to speed up compilation.\n",
      "  warnings.warn(\"Objective contains too many subexpressions. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuadProgOptimizer: start solving cvxpy problem...\n",
      "QuadProgOptimizer: cvxpy solve time = 3.317596197128296\n",
      "Estimation took time 11.138893842697144\n"
     ]
    }
   ],
   "source": [
    "from vsf.sensor import TareCalibrator\n",
    "from vsf.estimator.point_vsf_estimator import PointVSFEstimator, PointVSFEstimatorConfig\n",
    "from vsf.prior.prior_factory import GaussianVSFPriorFactory\n",
    "import time\n",
    "import copy\n",
    "vsf_est = vsf_empty\n",
    "vsf_empty = copy.deepcopy(vsf_est)  #save a copy of the uninitialized VSF for later\n",
    "\n",
    "#the second argument sets the prior estimate to a mean of 0.5 and a standard deviation of 1.0\n",
    "estimator = PointVSFEstimator(PointVSFEstimatorConfig(), GaussianVSFPriorFactory(0.5,1.0))\n",
    "\n",
    "t0 = time.time()\n",
    "estimator.batch_estimate(sim, vsf_est, [dataset[i] for i in range(5)], dataset_config, {sensor.name:TareCalibrator()})\n",
    "t1 = time.time()\n",
    "print(\"Estimation took time\",t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see some statistics about the estimates.  The VSF stiffness values are in the `stiffness` attribute, and it will also have new two features, 'K_std' and 'N_obs', which give the standard deviations of the estimates and the number of frames in which each point has been touched, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['K_std', 'N_obs']\n",
      "Stiffness min -2.726397961849863e-20, max 28.396162033081055, mean 0.5455399751663208, std 0.6045356392860413\n",
      "Number of points touched 1040/20000\n",
      "Touched stiffness min -2.726397961849863e-20, max 28.396162033081055, mean 1.3757702112197876, std 2.5101892948150635\n"
     ]
    }
   ],
   "source": [
    "print('Features:',list(vsf_est.features.keys()))\n",
    "stiffness = vsf_est.stiffness.cpu().numpy()\n",
    "N_obs = vsf_est.features['N_obs'].cpu().numpy()\n",
    "touched_mask = N_obs > 0\n",
    "print('Stiffness min {}, max {}, mean {}, std {}'.format(np.min(stiffness),np.max(stiffness),np.average(stiffness),np.std(stiffness)))\n",
    "print('Number of points touched {}/{}'.format(np.sum(N_obs > 0),stiffness.shape[0]))\n",
    "print('Touched stiffness min {}, max {}, mean {}, std {}'.format(np.min(stiffness[touched_mask]),np.max(stiffness[touched_mask]),np.average(stiffness[touched_mask]),np.std(stiffness[touched_mask])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize the estimates. For clearer visualization, we will set the stiffness of the untouched points to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stiffness range:  -2.726398e-20 28.396162\n",
      "#########################################\n",
      "klampt.vis: Creating dialog on window 9\n",
      "#########################################\n",
      "vis.dialog(): waiting for window 9 on vis thread to complete....\n",
      "vis.dialog(): ... dialog done\n"
     ]
    }
   ],
   "source": [
    "vsf_est.stiffness[~touched_mask] = 0\n",
    "vis.debug(world=world.world, estimated_pc = vsf_to_point_cloud(vsf_est), origin = view.origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's check the accuracy of the predictions on the 5-sequence training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 0 joint torque RMSEs [0.73303994 3.80165088 1.03696311 1.99729094 0.70382661 0.39356196\n",
      " 0.12847682]\n",
      "Sequence 1 joint torque RMSEs [2.35298485 1.16985833 1.37596327 0.99714673 0.73072358 0.43228238\n",
      " 0.26002846]\n",
      "Sequence 2 joint torque RMSEs [3.80693566 0.68984184 1.4025449  0.94029851 0.2939409  0.18091059\n",
      " 0.28451421]\n",
      "Sequence 3 joint torque RMSEs [1.87975762 0.91273379 1.31222036 0.9972302  0.32634134 0.46176164\n",
      " 0.20817396]\n",
      "Sequence 4 joint torque RMSEs [0.28476413 0.41272718 0.29000763 0.770336   0.11368901 0.18179088\n",
      " 0.22560368]\n"
     ]
    }
   ],
   "source": [
    "for seqno in range(len(dataset)):\n",
    "    #extract the sequence of controls and observations.  This is boilerplate\n",
    "    seq = dataset[seqno]\n",
    "    control_seq = []\n",
    "    sensor_seq = []\n",
    "    for frame in seq:\n",
    "        control_seq.append({k:frame[v] for k,v in dataset_config.control_keys.items()})\n",
    "        sensor_seq.append({k:frame[v] for k,v in dataset_config.sensor_keys.items()})\n",
    "        \n",
    "    #run the calibration\n",
    "    sim.reset()\n",
    "    n = calibrator.calibrate(sensor,sim,control_seq,sensor_seq)\n",
    "\n",
    "    #now, run the simulator and compare the predicted torques to the actual torques\n",
    "    dt = 0.1  # a guessed time step.  There's no time-dependent functionality in the quasistatic simulator, so this doesn't matter\n",
    "    diffs = []\n",
    "    for frameno in range(n,len(seq)):\n",
    "        sim.step(control_seq[frameno],dt)\n",
    "        pred = sim.measurements()['kinova_joint_torques']\n",
    "        actual = sensor_seq[frameno]['kinova_joint_torques']\n",
    "        assert len(pred) == len(actual)\n",
    "        diffs.append(pred-actual)\n",
    "    diffs = np.array(diffs)\n",
    "    print(\"Sequence\",seqno,\"joint torque RMSEs\",np.sqrt(np.mean(diffs**2,axis=0)))\n",
    "\n",
    "    if seqno >= 4: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since comparisons are done frequently, we also have standard functions for calculating these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 0 joint torque RMSEs [0.7493814  3.79082726 0.84790059 2.06831264 0.71367177 0.91755065\n",
      " 0.20167259]\n",
      "Sequence 1 joint torque RMSEs [2.43529267 1.18730576 1.57005884 1.08928811 0.72808527 0.67161187\n",
      " 0.3530975 ]\n",
      "Sequence 2 joint torque RMSEs [3.92197014 0.70663039 1.41258548 1.14950111 0.29892019 0.50347354\n",
      " 0.19000611]\n",
      "Sequence 3 joint torque RMSEs [1.87975762 0.91273379 1.31222036 0.9972302  0.32634134 0.46176164\n",
      " 0.20817396]\n",
      "Sequence 4 joint torque RMSEs [0.28476413 0.41272718 0.29000763 0.770336   0.11368901 0.18179088\n",
      " 0.22560368]\n",
      "Original RMSE train 2.6640317962954736\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704084155\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704084218\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704084271\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704084316\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704084378\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704084443\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704084485\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704084522\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704084581\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704084644\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704084688\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704084753\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704084797\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704084868\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704084930\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704084970\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704085016\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704085061\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704085107\n",
      "Loading sequence ../demo_data/kinova_joint_torques_dataset/rubber_fig_tall_angle00_trail1/arm/seq_1704085148\n",
      "Original RMSE test 1.1453552871824024\n",
      "Estimated RMSE train 1.4865889175470333\n",
      "Estimated RMSE test 1.0954882287871175\n"
     ]
    }
   ],
   "source": [
    "from vsf.sim.metrics import rmse_sensors\n",
    "calibrators = {'kinova_joint_torques':calibrator}\n",
    "rmses = rmse_sensors(sim,[dataset[i] for i in range(5)],dataset_config,calibrators)\n",
    "for i in range(5):\n",
    "    print(\"Sequence\",i,\"joint torque RMSEs\",rmses['kinova_joint_torques'][i])\n",
    "sim.vsf_objects['vsf'].vsf_model = vsf_empty\n",
    "print(\"Original RMSE train\",rmse_sensors(sim,[dataset[i] for i in range(5)],dataset_config,calibrators,aggregate_seqs=True,aggregate_channels=True)['kinova_joint_torques'])\n",
    "print(\"Original RMSE test\",rmse_sensors(sim,[dataset[i] for i in range(5,30)],dataset_config,calibrators,aggregate_seqs=True,aggregate_channels=True)['kinova_joint_torques'])\n",
    "sim.vsf_objects['vsf'].vsf_model = vsf_est\n",
    "print(\"Estimated RMSE train\",rmse_sensors(sim,[dataset[i] for i in range(5)],dataset_config,calibrators,aggregate_seqs=True,aggregate_channels=True)['kinova_joint_torques'])\n",
    "print(\"Estimated RMSE test\",rmse_sensors(sim,[dataset[i] for i in range(5,30)],dataset_config,calibrators,aggregate_seqs=True,aggregate_channels=True)['kinova_joint_torques'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that we've done a much better job of estimating the RMSEs on the training set but we haven't really improved the testing RMSEs very much.  This is because we've only used 5 sequences for training, and they may have not done a good job of covering the object.  This is a typical issue with using touch data alone.  Read on to the next section to explore better ways of extrapolating using vision features and priors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrapolating VSF data by color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating VSFs for bodies that move\n",
    "\n",
    "TODO: will need to load the pose from the dataset for each frame, update `vsf_body.pose`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating VSFs for hand-held tactile sensors\n",
    "\n",
    "TODO: will need to create an empty rigid body in the `klamptWorldWrapper` and attach the tactile sensor to the body. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-sensor estimation\n",
    "\n",
    "The estimation techniques above can work for any number of sensors.  Simply create more sensors to add to the simulator, and set up the observations dictionary to the estimator appropriately.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
