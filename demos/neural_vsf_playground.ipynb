{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#if you haven't installed vsf and just want to run this from the current directory, uncomment the following lines\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the demo data from box (80MB): \n",
    "+ #### Demo data: https://uofi.box.com/s/31wozq63qgqvg8012r1jdfj5mdchmmfp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize VSF\n",
    "\n",
    "We have already estimated some neural VSFs for you in the demo dataset.  To visualize them, you can use the `vsf_show` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# demo data directory\n",
    "DEMO_DIR = \"../demo_data\" # change to your path\n",
    "OBJECT = \"brown_boot_moving\" # choose from \"brown_boot_fixed\" or \"brown_boot_moving\"\n",
    "DATA_DIR = os.path.join(DEMO_DIR, 'datasets', OBJECT)\n",
    "TRIAL = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize VSF\n",
    "from vsf.constructors import vsf_from_file\n",
    "import torch\n",
    "\n",
    "#estimated VSFs have been saved to the \"outputs\" folder\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vsf = vsf_from_file(os.path.join(DEMO_DIR, \"saved_vsfs\", OBJECT, \"neural_vsf.pt\")).to(device)\n",
    "\n",
    "from klampt import vis\n",
    "from vsf.visualize.klampt_visualization import vsf_show\n",
    "vis.init('PyQt')  #needed inside Jupyter Notebook to show an OpenGL window\n",
    "vsf_show(vsf)\n",
    "vis.clear()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walkthrough neural VSF training and visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a world and simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import klampt\n",
    "from klampt.math import se3\n",
    "from vsf.sim import QuasistaticVSFSimulator\n",
    "from vsf.sensor.punyo_dense_force_sensor import PunyoDenseForceSensor\n",
    "from vsf.sim.klampt_world_wrapper import klamptWorldWrapper\n",
    "from vsf.utils.klampt_utils import load_trimesh_preserve_vertices\n",
    "\n",
    "# NOTE: This part of the code shows how to manually setup a simulation world with a robot, a tactile sensor and a deformable object,\n",
    "#       and how to estimate the VSF from tactile data.\n",
    "#       A script to automate this process from config files is in scripts/neural_vsf_estimate.py\n",
    "\n",
    "# create a world for simulation and visualization\n",
    "world = klamptWorldWrapper()\n",
    "\n",
    "# add robot/mesh to the world\n",
    "world.add_robot('kinova', os.path.join('../knowledge/robot_model', 'kinova_gen3.urdf'))\n",
    "robot = world.world.robot(0)\n",
    "ee_link = robot.link(robot.numLinks()-1)\n",
    "punyo2ee = np.array(json.load(open(os.path.join('../knowledge/robot_model', 'punyo2end_effector_transform.json')))['punyo2ee'])\n",
    "\n",
    "#this function should be used instead of native Klampt loaders due to a known Assimp configuration issue\n",
    "mesh = load_trimesh_preserve_vertices(os.path.join('../knowledge/robot_model', 'punyo_mesh_partial.ply'))\n",
    "world.add_geometry('punyo', mesh, 'deformable', ee_link.getName(), punyo2ee)\n",
    "\n",
    "# adds the VSF object to the world, for visualization purposes\n",
    "# hack for add object to the visualization without interfering with the simulator\n",
    "world2 = klampt.WorldModel()\n",
    "object = world2.makeRigidObject(\"object\")\n",
    "if os.path.exists(os.path.join(DATA_DIR, \"object\", \"mesh.obj\")):\n",
    "    object.geometry().loadFile(os.path.join(DATA_DIR, \"object\", \"mesh.obj\"))\n",
    "else:\n",
    "    aabb = np.load(os.path.join(DATA_DIR, \"object\", \"aabb.npy\"))\n",
    "    object.geometry().setTriangleMesh(klampt.model.create.primitives.bbox(*aabb).getTriangleMesh())\n",
    "\n",
    "# initialize sensors\n",
    "sensors = [PunyoDenseForceSensor('punyo', 'punyo')] # add sensor named 'punyo' and attach it to the mesh named 'punyo'\n",
    "\n",
    "# create simulator\n",
    "sim = QuasistaticVSFSimulator(world, sensors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tactile dataset and visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dacite\n",
    "from vsf.dataset.constructors import dataset_from_config, DatasetConfig\n",
    "\n",
    "from vsf.utils.config_utils import load_config_recursive\n",
    "config = load_config_recursive(os.path.join('../configs/neural_vsf_dense_forces.yaml'))\n",
    "dataset_config = dacite.from_dict(DatasetConfig, config['dataset'])\n",
    "dataset_config.path = os.path.join('../demo_data/datasets', OBJECT, TRIAL)\n",
    "dataset = dataset_from_config(dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from klampt import vis\n",
    "vis.init('PyQt')  #needed inside Jupyter Notebook to show an OpenGL window\n",
    "vis.clear()\n",
    "vis.add(\"world\", world.world)\n",
    "\n",
    "# add table\n",
    "# the table are for visualization only, not added to the simulator to avoid extra computation in the simulation\n",
    "from klampt.model.create import box\n",
    "b1 = box(3.0,3.0,1.1,center=(0,0,-0.55),type='GeometricPrimitive')\n",
    "vis.add(\"table\", b1, hide_label=True)\n",
    "b2 = box(1.2,1.,0.12,center=(0.5,0.7,0),type='GeometricPrimitive')\n",
    "vis.add(\"box\", b2, hide_label=True)\n",
    "\n",
    "# add visualization object to show its estimated pose\n",
    "vis.add(\"object\", object)\n",
    "vis.show()\n",
    "\n",
    "import time\n",
    "for i in range(len(dataset)):\n",
    "    seq = dataset[i]\n",
    "    for frame in seq:\n",
    "        control = {}\n",
    "        control['kinova'] = frame['angles']\n",
    "        control['punyo'] = frame['punyo_deformed']\n",
    "\n",
    "        # step simulation\n",
    "        vis.lock()\n",
    "        sim.step(control, 0.1)\n",
    "        object.setTransform(*se3.from_ndarray(frame['object_pose'])) # object mesh is for visualization only, so not added to the simulator\n",
    "        vis.unlock()\n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    sim.reset()\n",
    "    if i >= 5:\n",
    "        break\n",
    "vis.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create VSF model\n",
    "import torch\n",
    "from vsf.constructors import vsf_from_box, vsf_from_mesh\n",
    "\n",
    "# create vsf from a bounding box\n",
    "# aabb = np.load(os.path.join(DATA_DIR, \"object\", \"aabb.npy\"))\n",
    "# vsf = vsf_from_box(aabb[0], aabb[1], type='neural')\n",
    "\n",
    "# create vsf from a mesh -- this will do a better job estimating stiffness at the object boundaries\n",
    "vsf = vsf_from_mesh(os.path.join(DATA_DIR, \"object\", \"mesh.obj\"))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vsf = vsf.to(device)\n",
    "\n",
    "# add vsf to the scene\n",
    "sim.add_deformable('boot',vsf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run estimation\n",
    "\n",
    "The following code runs a batch estimation over the whole dataset.  Note that training is performed by randomizing over sequences in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch VSF estimation demo\n",
    "from vsf.estimator.neural_vsf_estimator import NeuralVSFEstimator, NeuralVSFEstimatorConfig\n",
    "\n",
    "# create estimator\n",
    "estimator_config = NeuralVSFEstimatorConfig(lr=2e-4,\n",
    "                                            regularizer_samples=500,\n",
    "                                            regularizer_scale=1e-4,\n",
    "                                            max_epochs=500)\n",
    "estimator = NeuralVSFEstimator(estimator_config)\n",
    "\n",
    "print(\"Starting batch estimation, using device\",vsf.device)\n",
    "estimator.batch_estimate(sim, vsf, dataset, dataset_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code runs an online estimation for each sequence in the dataset.  This does have a risk of catastrophic forgetting, since there is no memory replay buffer (as in Point VSF online estimators)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online VSF estimation demo\n",
    "\n",
    "# create estimator\n",
    "estimator_config = NeuralVSFEstimatorConfig(lr=2e-4,\n",
    "                                            regularizer_samples=500,\n",
    "                                            regularizer_scale=1e-4)\n",
    "estimator = NeuralVSFEstimator(estimator_config)\n",
    "\n",
    "estimator.online_init(sim, vsf)\n",
    "\n",
    "sensor_keys = dataset_config.sensor_keys\n",
    "control_keys = dataset_config.control_keysdt = 0.1\n",
    "\n",
    "dt = 0.1\n",
    "for i in range(len(dataset)):\n",
    "    print(\"Beginning sequence\",i)\n",
    "    seq = dataset[i]\n",
    "    sim.reset()\n",
    "    estimator.online_reset(sim)\n",
    "    for frame in seq:\n",
    "        control, observation = {}, {}\n",
    "        for k in sensor_keys:\n",
    "            observation[k] = frame[sensor_keys[k]]\n",
    "        for k in control_keys:\n",
    "            control[k] = frame[control_keys[k]]\n",
    "\n",
    "        sim.step(control, dt)\n",
    "        loss = estimator.online_update(sim, dt, observation)\n",
    "        print(\"Loss\",loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize VSF\n",
    "from vsf.visualize.klampt_visualization import vsf_show\n",
    "vsf_show(vsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk        \n",
    "os.makedirs(os.path.join(DEMO_DIR, \"outputs\", OBJECT), exist_ok=True)\n",
    "vsf.save(os.path.join(DEMO_DIR, \"outputs\", OBJECT, \"neural_vsf_playground.pt\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural VSF to Point VSF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vsf.constructors import vsf_from_vsf, PointVSFConfig\n",
    "\n",
    "voxel_size = 3e-3\n",
    "point_config = PointVSFConfig(voxel_size=voxel_size)\n",
    "point_vsf = vsf_from_vsf(point_config, vsf)\n",
    "vsf_show(point_vsf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point VSF to Neural VSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vsf.constructors import vsf_from_vsf, NeuralVSFConfig\n",
    "\n",
    "neural_config = NeuralVSFConfig()\n",
    "neural_vsf = vsf_from_vsf(neural_config, point_vsf)\n",
    "vsf_show(neural_vsf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vsf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
